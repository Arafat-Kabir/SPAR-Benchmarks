{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64251b03",
   "metadata": {},
   "source": [
    "# Fixed Point Precision Study on MLP-100 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32672482",
   "metadata": {},
   "source": [
    "This note book is the final stage of the model preparation for benchmarking. The next stage after this notebook is to simply implement the model in C using the knowledge gained from this notebook.  \n",
    "The fixed-point operations defined here tries to simulate the computations performed in SPAR. This might change over-time.\n",
    "\n",
    "**NOTE:**\n",
    "- The programs/code-snippets in this notebook follows C-like interfaces on purpose.\n",
    "- This is done so that, these code can be easily translated into C for the next stage of study."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5286025",
   "metadata": {},
   "source": [
    "# SQLite3 Database Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbd3e77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "# Returns a list of table names in the database file\n",
    "def getTableNames(db_path):\n",
    "    # Connect to the SQLite database\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Fetch the table names\n",
    "    cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "    table_names = cursor.fetchall()\n",
    "    table_names = [name[0] for name in table_names]  # make a list to return\n",
    "    conn.close()\n",
    "    return table_names\n",
    "\n",
    "\n",
    "# Returns a list of column names of the specified table\n",
    "def getColNames(database_filename, table_name):\n",
    "    # Connect to the SQLite database\n",
    "    conn = sqlite3.connect(database_filename)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Fetch the column names\n",
    "    cursor.execute(f\"PRAGMA table_info({table_name})\")\n",
    "    results = cursor.fetchall()\n",
    "    column_names = [result[1] for result in results]  # Extract the column names from the query results\n",
    "\n",
    "    # Close the connection and return \n",
    "    conn.close()\n",
    "    return column_names\n",
    "\n",
    "    \n",
    "# returns all records of a given table\n",
    "def getRecords(db_path, table_name):\n",
    "    # Connect to the SQLite database\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cursor = conn.cursor()\n",
    "    # Fetch all records from the table\n",
    "    cursor.execute(f\"SELECT * FROM {table_name}\")\n",
    "    records = cursor.fetchall()\n",
    "    return records\n",
    "\n",
    "\n",
    "# Checks if a table exist\n",
    "def existTable(db_path, table_name):\n",
    "    # Connect to the SQLite database\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cursor = conn.cursor()\n",
    "    # Check if the table exists\n",
    "    cursor.execute(f\"SELECT name FROM sqlite_master WHERE type='table' AND name='{table_name}'\")\n",
    "    result = cursor.fetchone()\n",
    "    if result is None: exist = False\n",
    "    else: exist = True\n",
    "    # Commit the changes and close the connection and return result\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "    return exist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456482ad",
   "metadata": {},
   "source": [
    "# Load Floating-Point Model Parameters and Dataset\n",
    "\n",
    "Here, the model and the dataset exported by the Numpy model extraction notebook is loaded and verified."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ea3cea",
   "metadata": {},
   "source": [
    "## Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f09da043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "table_names: ['Header', 'sqlite_sequence', 'Labels_T', 'DataItems_T', 'Features_T']\n",
      "\n",
      "('name', 'MNIST-Test')\n",
      "('feature_length', 784)\n",
      "('accuracy', 98.36)\n",
      "('labels.table', 'Labels_T')\n",
      "('dataset.table', 'DataItems_T')\n",
      "('dataitem.schema', '')\n",
      "('features.table', 'Features_T')\n",
      "\n",
      "Data_table: DataItems_T\n",
      "Feature_table: Features_T\n",
      "Label_table: Labels_T\n"
     ]
    }
   ],
   "source": [
    "# Load and check the dataset table\n",
    "Dataset_path = './saved/mnist_test_data-98.36p.s3db'\n",
    "\n",
    "table_names = getTableNames(Dataset_path)\n",
    "print('table_names:', table_names)\n",
    "\n",
    "# Read the header table\n",
    "header_records =  getRecords(Dataset_path, 'Header')\n",
    "header_dict = {}\n",
    "print('')\n",
    "for r in header_records: \n",
    "    print(r[1:3])\n",
    "    header_dict[r[1]] = r[2]\n",
    "    \n",
    "# Get the table names\n",
    "Data_table = header_dict['dataset.table']\n",
    "Feature_table = header_dict['features.table']\n",
    "Label_table = header_dict['labels.table']\n",
    "print('')\n",
    "print('Data_table:', Data_table)\n",
    "print('Feature_table:', Feature_table)\n",
    "print('Label_table:', Label_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2942128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_records: [(0, '0'), (1, '1'), (2, '2'), (3, '3'), (4, '4'), (5, '5'), (6, '6'), (7, '7'), (8, '8'), (9, '9')]\n",
      "Label_to_index: {'0': 0, '1': 1, '2': 2, '3': 3, '4': 4, '5': 5, '6': 6, '7': 7, '8': 8, '9': 9}\n",
      "Index_to_label: {0: '0', 1: '1', 2: '2', 3: '3', 4: '4', 5: '5', 6: '6', 7: '7', 8: '8', 9: '9'}\n"
     ]
    }
   ],
   "source": [
    "# Read the label_to_index dictionary\n",
    "labels_records = getRecords(Dataset_path, Label_table)\n",
    "print('labels_records:', labels_records)\n",
    "\n",
    "Label_to_index = {label:index for (index, label) in labels_records}\n",
    "Index_to_label = {index:label for (index, label) in labels_records}\n",
    "print('Label_to_index:', Label_to_index)\n",
    "print('Index_to_label:', Index_to_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982c0fec",
   "metadata": {},
   "source": [
    "### Build the Dataset array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b65fe35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import dataclasses\n",
    "from dataclasses import dataclass\n",
    "from typing import List\n",
    "\n",
    "\n",
    "# Dataset item class\n",
    "@dataclass\n",
    "class DataItem:\n",
    "    label: str\n",
    "    label_index: int\n",
    "    predicted_index: int\n",
    "    feature_vec: List[np.float32]\n",
    "        \n",
    "    def getItemSummary(self):\n",
    "        return str((self.label, self.label_index, self.predicted_index, self.feature_vec.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62c76c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_schema: ['id', 'label', 'label_index', 'predicted_index', 'feature_id']\n",
      "Dataset: 10000\n",
      "item: ('7', 7, 7, (784,))\n"
     ]
    }
   ],
   "source": [
    "# Read the features and data-item records then merge them\n",
    "# Make the feature_id:feature_vec map\n",
    "feat_records = getRecords(Dataset_path, Feature_table)\n",
    "featid_map = {}\n",
    "for r in feat_records:\n",
    "    feat_id = r[0]       # first column is the feature ID\n",
    "    feat_vec = r[1:]\n",
    "    featid_map[feat_id]  = feat_vec\n",
    "\n",
    "# Read the data-items and put them in DataItem array\n",
    "Dataset = []\n",
    "data_records = getRecords(Dataset_path, Data_table)\n",
    "data_schema = getColNames(Dataset_path, Data_table)\n",
    "print('data_schema:', data_schema)\n",
    "\n",
    "for r in data_records:\n",
    "    label = r[1]\n",
    "    label_index = r[2]\n",
    "    pred_index = r[3]\n",
    "    feat_id = r[4]\n",
    "    feat_vec = np.array(featid_map[feat_id], dtype=np.float32)\n",
    "    item = DataItem(label, label_index, pred_index, feat_vec)\n",
    "    Dataset.append(item)\n",
    "\n",
    "item = Dataset[0]\n",
    "print('Dataset:', len(Dataset))\n",
    "print('item:', item.getItemSummary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0236da",
   "metadata": {},
   "source": [
    "## Load the Trained Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17ee1940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "table_names: ['Header', 'sqlite_sequence', 'Hparam_T', 'FC1_Weight_T', 'FC2_Weight_T', 'FC3_Weight_T', 'FC1_Bias_T', 'FC2_Bias_T', 'FC3_Bias_T']\n",
      "\n",
      "('name', 'MLP-100')\n",
      "('architecture', '784-FC:100-FC:100-10')\n",
      "('accuracy', 98.36)\n",
      "('correct_count', 9836)\n",
      "('Hparam.table', 'Hparam_T')\n",
      "('fc1.weight.table', 'FC1_Weight_T')\n",
      "('fc1.bias.table', 'FC1_Bias_T')\n",
      "('fc2.weight.table', 'FC2_Weight_T')\n",
      "('fc2.bias.table', 'FC2_Bias_T')\n",
      "('fc3.weight.table', 'FC3_Weight_T')\n",
      "('fc3.bias.table', 'FC3_Bias_T')\n"
     ]
    }
   ],
   "source": [
    "# Load and check the dataset table\n",
    "Model_path = './saved/trained_mlp100-98.36p.s3db'\n",
    "\n",
    "table_names = getTableNames(Model_path)\n",
    "print('table_names:', table_names)\n",
    "\n",
    "# Read the header table\n",
    "header_records =  getRecords(Model_path, 'Header')\n",
    "Header_dict = {}\n",
    "print('')\n",
    "for r in header_records: \n",
    "    print(r[1:3])\n",
    "    Header_dict[r[1]] = r[2]\n",
    "\n",
    "\n",
    "\n",
    "# Get the table names for later use\n",
    "Fc1w_table = Header_dict['fc1.weight.table']\n",
    "Fc1b_table = Header_dict['fc1.bias.table']\n",
    "Fc2w_table = Header_dict['fc2.weight.table']\n",
    "Fc2b_table = Header_dict['fc2.bias.table']\n",
    "Fc3w_table = Header_dict['fc3.weight.table']\n",
    "Fc3b_table = Header_dict['fc3.bias.table']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53b33abf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 784)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Returns a table saved using createMatrixTable as a list of tuples\n",
    "def readMatrixTable(db_path, table_name):\n",
    "    # read the records\n",
    "    rec_list = getRecords(db_path, table_name)\n",
    "    # build the matrix\n",
    "    rec_list.sort()         # sort by row_no (first column)\n",
    "    matrix = []\n",
    "    for rec in rec_list:\n",
    "        matrix.append(rec[1:])  # stripe off the row_no columns\n",
    "    return matrix\n",
    "\n",
    "\n",
    "# test this functions\n",
    "mat1 = np.array(readMatrixTable(Model_path, Fc1w_table))\n",
    "mat1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f13b7c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ParamTable_names: ['FC1_Weight_T', 'FC1_Bias_T', 'FC2_Weight_T', 'FC2_Bias_T', 'FC3_Weight_T', 'FC3_Bias_T']\n",
      "FC1_Weight_T: (100, 784) float64\n",
      "FC1_Bias_T: (100,) float64\n",
      "FC2_Weight_T: (100, 100) float64\n",
      "FC2_Bias_T: (100,) float64\n",
      "FC3_Weight_T: (10, 100) float64\n",
      "FC3_Bias_T: (10,) float64\n"
     ]
    }
   ],
   "source": [
    "# Returns the weights and biases as a dictionary\n",
    "def readModelParam(db_path, table_names):\n",
    "    model_params = {}\n",
    "    for name in table_names:\n",
    "        # read the matrix as a list of tuples\n",
    "        mat = readMatrixTable(db_path, name)\n",
    "        # Check if it is a matrix or a vector\n",
    "        if len(mat)==1: is_vector = True\n",
    "        else: is_vector = False\n",
    "        # convert to numpy array\n",
    "        if is_vector: mat = np.array(mat[0])    # make a 1D array for vectors\n",
    "        else: mat = np.array(mat)\n",
    "        # save it for returning\n",
    "        model_params[name] = mat\n",
    "    return model_params\n",
    "\n",
    "# List of table names for running loop\n",
    "ParamTable_names = [\n",
    "    Fc1w_table,\n",
    "    Fc1b_table,\n",
    "    Fc2w_table,\n",
    "    Fc2b_table,\n",
    "    Fc3w_table,\n",
    "    Fc3b_table\n",
    "]\n",
    "print('ParamTable_names:', ParamTable_names)\n",
    "\n",
    "# Read the model parameters as numpy matrix/vectors\n",
    "model_params = readModelParam(Model_path, ParamTable_names)\n",
    "for k, v in model_params.items():\n",
    "    print(f'{k}:', v.shape, v.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71155ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fc1_weight: (100, 784) float32\n",
      "fc2_weight: (100, 100) float32\n",
      "fc3_weight: (10, 100) float32\n",
      "fc1_bias: (100,) float32\n",
      "fc2_bias: (100,) float32\n",
      "fc3_bias: (10,) float32\n"
     ]
    }
   ],
   "source": [
    "# Model Parameters class\n",
    "@dataclass\n",
    "class mlp100_Params:\n",
    "    fc1_weight: np.ndarray\n",
    "    fc2_weight: np.ndarray\n",
    "    fc3_weight: np.ndarray\n",
    "    fc1_bias: np.ndarray\n",
    "    fc2_bias: np.ndarray\n",
    "    fc3_bias: np.ndarray\n",
    "        \n",
    "\n",
    "# Instantiate the model parameter class with float32 datatype\n",
    "Model_params = mlp100_Params(\n",
    "    model_params[Fc1w_table].astype(np.float32),\n",
    "    model_params[Fc2w_table].astype(np.float32),\n",
    "    model_params[Fc3w_table].astype(np.float32),\n",
    "    model_params[Fc1b_table].astype(np.float32),\n",
    "    model_params[Fc2b_table].astype(np.float32),\n",
    "    model_params[Fc3b_table].astype(np.float32)\n",
    ")\n",
    "\n",
    "# Show the parameter info\n",
    "for field in dataclasses.fields(Model_params):\n",
    "    field_value = getattr(Model_params, field.name)\n",
    "    print(field.name+':', field_value.shape, field_value.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71fb68f9",
   "metadata": {},
   "source": [
    "# Verify the Model on the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc6d416a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred: 7\n",
      "('7', 7, 7, (784,))\n"
     ]
    }
   ],
   "source": [
    "# Relu on numpy array\n",
    "def npReLU(np_arr):\n",
    "    return np.maximum(0, np_arr)\n",
    "\n",
    "\n",
    "# Performs the forward inference on the mlp100 model\n",
    "# params: model parameters, an instance of mlp100_Params\n",
    "def mlp100_forward(params, feature_vec):\n",
    "    x1 = params.fc1_weight @ feature_vec + params.fc1_bias\n",
    "    fc1_out = npReLU(x1)\n",
    "    x2 = params.fc2_weight @ fc1_out + params.fc2_bias\n",
    "    fc2_out = npReLU(x2)\n",
    "    fc3_out = params.fc3_weight @ fc2_out + params.fc3_bias\n",
    "    return fc3_out\n",
    "\n",
    "# Uses the forward pass and converts the result into predicted_index\n",
    "def mlp100_predict(params, feature_vec):\n",
    "    out_vec = mlp100_forward(params, feature_vec)\n",
    "    return np.argmax(out_vec)   # return the index of the highest probable class\n",
    "\n",
    "\n",
    "# Test this model\n",
    "item = Dataset[0]\n",
    "pred = mlp100_predict(Model_params, item.feature_vec)\n",
    "print('pred:', pred)\n",
    "print(item.getItemSummary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5a5d613",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "795e0ef36def4676b0bf5a0fbc876b84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 98.36%   correct_count: 9836   expected-miss: 0   total_count: 10000\n",
      "Expected:  accuracy: 98.36%   correct_count: 9836\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "# Validate the Given model on the whole dataset\n",
    "# model_params: instance of mlp100_Params\n",
    "# model_predict: a function that takes model_params and a feacture_vec to compute predicted_index\n",
    "def validateModel(model_params, model_predict):\n",
    "    expect_miss = 0      # keeps track of no. of mismatche between prediction in dataset vs model prediction\n",
    "    total_count = 0\n",
    "    correct_count = 0\n",
    "    for item in tqdm(Dataset):\n",
    "        pred_index = model_predict(model_params, item.feature_vec)\n",
    "        if pred_index != item.predicted_index: expect_miss += 1    # prediction does not match prediction in dataset\n",
    "        if pred_index == item.label_index: correct_count += 1   # prediction matched the actual label-index\n",
    "        total_count += 1\n",
    "    # Compute and print statistics\n",
    "    accuracy = (100.0 * correct_count) / total_count\n",
    "    print(f'Validation accuracy: {accuracy:.2f}%   correct_count: {correct_count}   expected-miss: {expect_miss}   total_count: {total_count}')\n",
    "    return accuracy, correct_count, expect_miss, total_count\n",
    "\n",
    "\n",
    "validateModel(Model_params, mlp100_predict)\n",
    "print(f'Expected:  accuracy: {Header_dict[\"accuracy\"]}%', '  correct_count:', Header_dict['correct_count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513e1458",
   "metadata": {},
   "source": [
    "# Define Fixed-Point Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fdbae02",
   "metadata": {},
   "source": [
    "## Data Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "532a00ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixed-point datatype (struct)\n",
    "@dataclass\n",
    "class fxp_FixedPoint:\n",
    "    _total_width: int\n",
    "    _frac_width: int\n",
    "    _scale_fact: int\n",
    "    _data: np.ndarray\n",
    "    _basetype: None    # will be initialize by constructor, should match _data.dtype\n",
    "\n",
    "\n",
    "# This class can be used to retrieved the status of operation\n",
    "@dataclass\n",
    "class fxp_Status:\n",
    "    overflow: bool\n",
    "    # maximum value in integer representation\n",
    "    max_vali: int \n",
    "    min_vali: int\n",
    "    # maximum value in floating-point representation\n",
    "    max_valf: float\n",
    "    min_valf: float\n",
    "\n",
    "        \n",
    "# fixed-point constructor: Returns a fixed-point object\n",
    "def fxp_ctor(total_width, frac_width, array, dtype=None):\n",
    "    assert frac_width <= total_width, \"Invalid widths specified\"\n",
    "    # Compute the derived parameters\n",
    "    scale = 2**frac_width    # scaling factor\n",
    "    #if dtype==None:\n",
    "    #    if total_width<=32: dtype = np.int32\n",
    "    #    else: dtype = np.int64\n",
    "    dtype = np.int64\n",
    "    # convert the input array into fixed-point integer representation\n",
    "    nparray = np.array(array) * scale   # scale the input numbers\n",
    "    nparray = nparray.astype(dtype)     # convert to integer type\n",
    "    fpitem = fxp_FixedPoint(total_width, frac_width, scale, nparray, dtype)\n",
    "    fxp_fitData(fpitem)                 # fit within the specified width\n",
    "    return fpitem\n",
    "\n",
    "\n",
    "# checks if given fixed-point numbers are compatible\n",
    "def fxp_isCompatible(a, b):\n",
    "    assert a._total_width == b._total_width, \"Total widths unequal\"\n",
    "    assert a._frac_width == b._frac_width, \"Fraction widths unequal\"\n",
    "    assert a._scale_fact == b._scale_fact, \"Scaling factor unequal\"\n",
    "    assert a._data.dtype == b._data.dtype, \"Base types are different\"\n",
    "    return True    # reaching this line means they are compatible\n",
    "\n",
    "    \n",
    "# Returns a bit-mask where the lower _total_width bits are 1s, \n",
    "# all other bits are zeros.\n",
    "def fxp_getMask(fxp_num):\n",
    "    mask = (1 << fxp_num._total_width) - 1\n",
    "    return mask\n",
    "\n",
    "\n",
    "# Returns an array where values are 0 or 1.\n",
    "# Elements with 1 in their _total_width (msb) bit position with 1 is 1 (negative number)\n",
    "# Elements with 0 in their _total_width (msb) bit posistion with 0 is 0 (positive number)\n",
    "def fxp_getSignBits(fxp_num):\n",
    "    msb_pos = fxp_num._total_width - 1         # msb index\n",
    "    sign_bits = fxp_num._data & (1<<msb_pos)   # zero/non-zero\n",
    "    sign_bits = np.where(sign_bits!=0, 1, 0)   # convert non-zeros to 1\n",
    "    return sign_bits\n",
    "\n",
    "\n",
    "# Returns an array as floating point number\n",
    "def fxp_getAsFloat(fxp_num):\n",
    "    retval = fxp_num._data.astype(np.float32) / fxp_num._scale_fact\n",
    "    return retval\n",
    "\n",
    "\n",
    "# Returns the _data array as an array of binary-representation string\n",
    "def fxp_getAsBin(fxp_num):\n",
    "    retval = []\n",
    "    for num in fxp_num._data: \n",
    "        retval.append(np.binary_repr(num))\n",
    "    return retval\n",
    "\n",
    "\n",
    "# Truncate the underlying data to fit the fixed-point precision.\n",
    "# This is done by duplicating the bit at MSb of the fixed-point for sign extension.\n",
    "def fxp_fitData(fxp_num):\n",
    "    mask = fxp_getMask(fxp_num)      # get the mask for bit selection\n",
    "    cleared = fxp_num._data & mask   # clear upper bits\n",
    "    imask = ~mask                    # inverted mask for sign extension of negative numbers\n",
    "    sign_bits = fxp_getSignBits(fxp_num)    # make negative number filter\n",
    "    fxp_num._data = cleared | (sign_bits * imask)  # set all upper bits to 1 of negative numbers (sign extension)\n",
    "    \n",
    "\n",
    "# Returns a representation string\n",
    "def fxp_repr(fxp_num):\n",
    "    mstr = ['fxp_FixedPoint:']\n",
    "    mstr.append(f'  total_width: {fxp_num._total_width}')\n",
    "    mstr.append(f'  frac_width: {fxp_num._frac_width}')\n",
    "    mstr.append(f'  data: type{type(fxp_num._data)}  base-type: {fxp_num._data.dtype}  shape: {fxp_num._data.shape}')\n",
    "    return '\\n'.join(mstr)\n",
    "\n",
    "\n",
    "# Returns an instance of fxp_FixedPoint with compatible parameters as template.\n",
    "# _data remains invalid.\n",
    "def fxp_makeSame(template):\n",
    "    retobj = fxp_FixedPoint(\n",
    "        template._total_width,\n",
    "        template._frac_width,\n",
    "        template._scale_fact,\n",
    "        None,\n",
    "        template._basetype, \n",
    "    )\n",
    "    return retobj\n",
    "\n",
    "\n",
    "# Returns a copy of the fixed-point number\n",
    "def fxp_copy(fxp_num):\n",
    "    retobj = fxp_makeSame(fxp_num)\n",
    "    retobj._data = fxp_num._data.copy()\n",
    "    return retobj\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3dc00454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fxp_FixedPoint(_total_width=8, _frac_width=4, _scale_fact=16, _data=array([16, 32, 48, 64, 80]), _basetype=<class 'numpy.int64'>)\n",
      "fxp_FixedPoint:\n",
      "  total_width: 8\n",
      "  frac_width: 4\n",
      "  data: type<class 'numpy.ndarray'>  base-type: int64  shape: (5,)\n",
      "[16 32 48 64 80]\n",
      "[1. 2. 3. 4. 5.]\n"
     ]
    }
   ],
   "source": [
    "# Prints a representation\n",
    "def fxp_printInfo(fxp_num):\n",
    "    print(fxp_repr(fxp_num))\n",
    "\n",
    "    \n",
    "# Prints the internal array (_data)\n",
    "def fxp_printData(fxp_num):\n",
    "    print(fxp_num._data)\n",
    "    \n",
    "\n",
    "# Prints the fixed point numbers as floating points\n",
    "def fxp_printValue(fxp_num):\n",
    "    nparr = fxp_getAsFloat(fxp_num)\n",
    "    print(nparr)\n",
    "    \n",
    "    \n",
    "\n",
    "# Test above functions\n",
    "num1 = fxp_ctor(8, 4, [1,2,3,4,5])\n",
    "print(num1)\n",
    "fxp_printInfo(num1)\n",
    "fxp_printData(num1)\n",
    "fxp_printValue(num1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f3c01f",
   "metadata": {},
   "source": [
    "### Unit Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1f9b4c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fxp_ctor() tests:\n",
      "[8, 9, 4, 2, 31, -3, -9]\n",
      "[-8. -7.  4.  2. -1. -3.  7.]\n",
      "\n",
      "[16, 18, -4, -32, 32, -10]\n",
      "[-16. -14.  -4.   0.   0. -10.]\n",
      "\n",
      "\n",
      "fxp_getSignBits() tests:\n",
      "[1, 1, 1, 0, 0, 0]\n",
      "[1 1 1 0 0 0]\n",
      "\n",
      "[1, 0, 1, 0, 1, 0]\n",
      "[1 0 1 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "# Testing fxp_ctor\n",
    "print('fxp_ctor() tests:')\n",
    "\n",
    "inp_vec = [ 8,  9, 4, 2, 31, -3, -9]\n",
    "out_vec = [-8, -7, 4, 2, -1, -3, 7]        # 8 -> -8, 9 -> -7, 31 -> -1\n",
    "fxp_tnum = fxp_ctor(8, 4, inp_vec)  \n",
    "print(inp_vec)\n",
    "fxp_printValue(fxp_tnum)\n",
    "#print(fxp_getAsBin(fxp_tnum))\n",
    "result = (out_vec == fxp_getAsFloat(fxp_tnum))\n",
    "assert result.all(), \"Problem with fxp_ctor\"\n",
    "\n",
    "print('')\n",
    "inp_vec = [ 16,  18, -4, -32, 32, -10]\n",
    "out_vec = [-16, -14, -4, 0, 0, -10]\n",
    "fxp_tnum = fxp_ctor(10, 5, inp_vec)  \n",
    "print(inp_vec)\n",
    "fxp_printValue(fxp_tnum)\n",
    "#print(fxp_getAsBin(fxp_tnum))\n",
    "result = (out_vec == fxp_getAsFloat(fxp_tnum))\n",
    "assert result.all(), \"Problem with fxp_ctor()\"\n",
    "\n",
    "\n",
    "# Testing fxp_getSignBits()\n",
    "print('\\n\\nfxp_getSignBits() tests:')\n",
    "\n",
    "inp_vec = [ -2, -4, -5, 4, 5, 7]\n",
    "out_vec = [1,1,1,0,0,0]\n",
    "fxp_tnum = fxp_ctor(8, 4, inp_vec)\n",
    "sign_bits = fxp_getSignBits(fxp_tnum)\n",
    "result = (sign_bits == out_vec)\n",
    "print(out_vec)\n",
    "print(sign_bits)\n",
    "assert result.all(), \"Problem with fxp_getSignBits()\"\n",
    "\n",
    "\n",
    "print('')\n",
    "inp_vec = [ -10, 14, -5, 14, -5, 7]\n",
    "out_vec = [1, 0, 1, 0, 1, 0]\n",
    "fxp_tnum = fxp_ctor(10, 5, inp_vec)\n",
    "sign_bits = fxp_getSignBits(fxp_tnum)\n",
    "result = (sign_bits == out_vec)\n",
    "print(out_vec)\n",
    "print(sign_bits)\n",
    "assert result.all(), \"Problem with fxp_getSignBits()\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1309ef94",
   "metadata": {},
   "source": [
    "## Math operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5f691e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adds to Fixed point numbers\n",
    "# status: instance of fxp_Status\n",
    "def fxp_add(a, b, status=None):\n",
    "    fxp_isCompatible(a, b)\n",
    "    sum_data = a._data + b._data\n",
    "    retobj = fxp_makeSame(a)\n",
    "    retobj._data = sum_data\n",
    "    return retobj\n",
    "    \n",
    "\n",
    "\n",
    "# Test functions\n",
    "num1 = fxp_ctor(8, 4, [1,2,3,4,5])\n",
    "num2 = fxp_ctor(8, 4, [1,2,3,4,5])\n",
    "num3 = fxp_add(num1, num2)\n",
    "fxp_printInfo(num3)\n",
    "fxp_printData(num3)\n",
    "fxp_printValue(num3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b08450e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = fxp_ctor(8, 4, [8,9,4,2,31])   # 8 -> -8, 9 -> -7, 31 -> -1\n",
    "fxp_printData(tmp)\n",
    "\n",
    "mask = fxp_getMask(tmp)\n",
    "print(bin(mask))\n",
    "imask = ~mask\n",
    "print(bin(imask))\n",
    "\n",
    "\n",
    "sign_bits = fxp_getSignBits(tmp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2e7e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove upper bits\n",
    "tmp2 = tmp._data & mask\n",
    "print(tmp2)\n",
    "\n",
    "# Copy sign bits in upper bits\n",
    "tmp2 = tmp2 | (sign_bits * imask)\n",
    "print(tmp2)\n",
    "print(tmp2 / 16.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a012871",
   "metadata": {},
   "outputs": [],
   "source": [
    "fxp_printValue(tmp)\n",
    "\n",
    "tmp3 = fxp_copy(tmp)\n",
    "fxp_printValue(tmp3)\n",
    "\n",
    "fxp_fitData(tmp3)\n",
    "fxp_printValue(tmp3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2eb215f",
   "metadata": {},
   "source": [
    "# Implement Model in Fixed-Point"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fbac1c",
   "metadata": {},
   "source": [
    "# Experiments for Fixed-Point Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec47e441",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c647a0b7",
   "metadata": {},
   "source": [
    "# Export Model and Dataset as SQLite3 DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39833208",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
