{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64251b03",
   "metadata": {},
   "source": [
    "# Fixed Point Precision Study on MLP-100 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32672482",
   "metadata": {},
   "source": [
    "This note book is the final stage of the model preparation for benchmarking. The next stage after this notebook is to simply implement the model in C using the knowledge gained from this notebook.  \n",
    "The fixed-point operations defined here tries to simulate the computations performed in SPAR. This might change over-time.\n",
    "\n",
    "**NOTE:**\n",
    "- The programs/code-snippets in this notebook follows C-like interfaces on purpose.\n",
    "- This is done so that, these code can be easily translated into C for the next stage of study."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5286025",
   "metadata": {},
   "source": [
    "# SQLite3 Database Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbd3e77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "# Returns a list of table names in the database file\n",
    "def getTableNames(db_path):\n",
    "    # Connect to the SQLite database\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Fetch the table names\n",
    "    cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "    table_names = cursor.fetchall()\n",
    "    table_names = [name[0] for name in table_names]  # make a list to return\n",
    "    conn.close()\n",
    "    return table_names\n",
    "\n",
    "\n",
    "# Returns a list of column names of the specified table\n",
    "def getColNames(database_filename, table_name):\n",
    "    # Connect to the SQLite database\n",
    "    conn = sqlite3.connect(database_filename)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Fetch the column names\n",
    "    cursor.execute(f\"PRAGMA table_info({table_name})\")\n",
    "    results = cursor.fetchall()\n",
    "    column_names = [result[1] for result in results]  # Extract the column names from the query results\n",
    "\n",
    "    # Close the connection and return \n",
    "    conn.close()\n",
    "    return column_names\n",
    "\n",
    "    \n",
    "# returns all records of a given table\n",
    "def getRecords(db_path, table_name):\n",
    "    # Connect to the SQLite database\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cursor = conn.cursor()\n",
    "    # Fetch all records from the table\n",
    "    cursor.execute(f\"SELECT * FROM {table_name}\")\n",
    "    records = cursor.fetchall()\n",
    "    return records\n",
    "\n",
    "\n",
    "# Checks if a table exist\n",
    "def existTable(db_path, table_name):\n",
    "    # Connect to the SQLite database\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cursor = conn.cursor()\n",
    "    # Check if the table exists\n",
    "    cursor.execute(f\"SELECT name FROM sqlite_master WHERE type='table' AND name='{table_name}'\")\n",
    "    result = cursor.fetchone()\n",
    "    if result is None: exist = False\n",
    "    else: exist = True\n",
    "    # Commit the changes and close the connection and return result\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "    return exist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456482ad",
   "metadata": {},
   "source": [
    "# Load Floating-Point Model Parameters and Dataset\n",
    "\n",
    "Here, the model and the dataset exported by the Numpy model extraction notebook is loaded and verified."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ea3cea",
   "metadata": {},
   "source": [
    "## Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f09da043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "table_names: ['Header', 'sqlite_sequence', 'Labels_T', 'DataItems_T', 'Features_T']\n",
      "\n",
      "('name', 'MNIST-Test')\n",
      "('feature_length', 784)\n",
      "('accuracy', 98.36)\n",
      "('labels.table', 'Labels_T')\n",
      "('dataset.table', 'DataItems_T')\n",
      "('dataitem.schema', '')\n",
      "('features.table', 'Features_T')\n",
      "\n",
      "Data_table: DataItems_T\n",
      "Feature_table: Features_T\n",
      "Label_table: Labels_T\n"
     ]
    }
   ],
   "source": [
    "# Load and check the dataset table\n",
    "Dataset_path = './saved/mnist_test_data-98.36p.s3db'\n",
    "\n",
    "table_names = getTableNames(Dataset_path)\n",
    "print('table_names:', table_names)\n",
    "\n",
    "# Read the header table\n",
    "header_records =  getRecords(Dataset_path, 'Header')\n",
    "header_dict = {}\n",
    "print('')\n",
    "for r in header_records: \n",
    "    print(r[1:3])\n",
    "    header_dict[r[1]] = r[2]\n",
    "    \n",
    "# Get the table names\n",
    "Data_table = header_dict['dataset.table']\n",
    "Feature_table = header_dict['features.table']\n",
    "Label_table = header_dict['labels.table']\n",
    "print('')\n",
    "print('Data_table:', Data_table)\n",
    "print('Feature_table:', Feature_table)\n",
    "print('Label_table:', Label_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2942128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_records: [(0, '0'), (1, '1'), (2, '2'), (3, '3'), (4, '4'), (5, '5'), (6, '6'), (7, '7'), (8, '8'), (9, '9')]\n",
      "Label_to_index: {'0': 0, '1': 1, '2': 2, '3': 3, '4': 4, '5': 5, '6': 6, '7': 7, '8': 8, '9': 9}\n",
      "Index_to_label: {0: '0', 1: '1', 2: '2', 3: '3', 4: '4', 5: '5', 6: '6', 7: '7', 8: '8', 9: '9'}\n"
     ]
    }
   ],
   "source": [
    "# Read the label_to_index dictionary\n",
    "labels_records = getRecords(Dataset_path, Label_table)\n",
    "print('labels_records:', labels_records)\n",
    "\n",
    "Label_to_index = {label:index for (index, label) in labels_records}\n",
    "Index_to_label = {index:label for (index, label) in labels_records}\n",
    "print('Label_to_index:', Label_to_index)\n",
    "print('Index_to_label:', Index_to_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982c0fec",
   "metadata": {},
   "source": [
    "### Build the Dataset array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b65fe35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import dataclasses\n",
    "from dataclasses import dataclass\n",
    "from typing import List\n",
    "\n",
    "\n",
    "# Dataset item class\n",
    "@dataclass\n",
    "class DataItem:\n",
    "    label: str\n",
    "    label_index: int\n",
    "    predicted_index: int\n",
    "    feature_vec: List[np.float32]\n",
    "        \n",
    "    def getItemSummary(self):\n",
    "        return str((self.label, self.label_index, self.predicted_index, self.feature_vec.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62c76c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_schema: ['id', 'label', 'label_index', 'predicted_index', 'feature_id']\n",
      "Dataset: 10000\n",
      "item: ('7', 7, 7, (784,))\n"
     ]
    }
   ],
   "source": [
    "# Read the features and data-item records then merge them\n",
    "# Make the feature_id:feature_vec map\n",
    "feat_records = getRecords(Dataset_path, Feature_table)\n",
    "featid_map = {}\n",
    "for r in feat_records:\n",
    "    feat_id = r[0]       # first column is the feature ID\n",
    "    feat_vec = r[1:]\n",
    "    featid_map[feat_id]  = feat_vec\n",
    "\n",
    "# Read the data-items and put them in DataItem array\n",
    "Dataset = []\n",
    "data_records = getRecords(Dataset_path, Data_table)\n",
    "data_schema = getColNames(Dataset_path, Data_table)\n",
    "print('data_schema:', data_schema)\n",
    "\n",
    "for r in data_records:\n",
    "    label = r[1]\n",
    "    label_index = r[2]\n",
    "    pred_index = r[3]\n",
    "    feat_id = r[4]\n",
    "    feat_vec = np.array(featid_map[feat_id], dtype=np.float32)\n",
    "    item = DataItem(label, label_index, pred_index, feat_vec)\n",
    "    Dataset.append(item)\n",
    "\n",
    "item = Dataset[0]\n",
    "print('Dataset:', len(Dataset))\n",
    "print('item:', item.getItemSummary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0236da",
   "metadata": {},
   "source": [
    "## Load the Trained Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6279b89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "table_names: ['Header', 'sqlite_sequence', 'Hparam_T', 'FC1_Weight_T', 'FC2_Weight_T', 'FC3_Weight_T', 'FC1_Bias_T', 'FC2_Bias_T', 'FC3_Bias_T']\n",
      "\n",
      "('name', 'MLP-100')\n",
      "('architecture', '784-FC:100-FC:100-10')\n",
      "('accuracy', 98.36)\n",
      "('correct_count', 9836)\n",
      "('Hparam.table', 'Hparam_T')\n",
      "('fc1.weight.table', 'FC1_Weight_T')\n",
      "('fc1.bias.table', 'FC1_Bias_T')\n",
      "('fc2.weight.table', 'FC2_Weight_T')\n",
      "('fc2.bias.table', 'FC2_Bias_T')\n",
      "('fc3.weight.table', 'FC3_Weight_T')\n",
      "('fc3.bias.table', 'FC3_Bias_T')\n"
     ]
    }
   ],
   "source": [
    "# Load and check the dataset table\n",
    "Model_path = './saved/trained_mlp100-98.36p.s3db'\n",
    "\n",
    "table_names = getTableNames(Model_path)\n",
    "print('table_names:', table_names)\n",
    "\n",
    "# Read the header table\n",
    "header_records =  getRecords(Model_path, 'Header')\n",
    "Header_dict = {}\n",
    "print('')\n",
    "for r in header_records: \n",
    "    print(r[1:3])\n",
    "    Header_dict[r[1]] = r[2]\n",
    "\n",
    "\n",
    "\n",
    "# Get the table names for later use\n",
    "Fc1w_table = Header_dict['fc1.weight.table']\n",
    "Fc1b_table = Header_dict['fc1.bias.table']\n",
    "Fc2w_table = Header_dict['fc2.weight.table']\n",
    "Fc2b_table = Header_dict['fc2.bias.table']\n",
    "Fc3w_table = Header_dict['fc3.weight.table']\n",
    "Fc3b_table = Header_dict['fc3.bias.table']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "613c0766",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 784)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Returns a table saved using createMatrixTable as a list of tuples\n",
    "def readMatrixTable(db_path, table_name):\n",
    "    # read the records\n",
    "    rec_list = getRecords(db_path, table_name)\n",
    "    # build the matrix\n",
    "    rec_list.sort()         # sort by row_no (first column)\n",
    "    matrix = []\n",
    "    for rec in rec_list:\n",
    "        matrix.append(rec[1:])  # stripe off the row_no columns\n",
    "    return matrix\n",
    "\n",
    "\n",
    "# test this functions\n",
    "mat1 = np.array(readMatrixTable(Model_path, Fc1w_table))\n",
    "mat1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83f51aa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ParamTable_names: ['FC1_Weight_T', 'FC1_Bias_T', 'FC2_Weight_T', 'FC2_Bias_T', 'FC3_Weight_T', 'FC3_Bias_T']\n",
      "FC1_Weight_T: (100, 784) float64\n",
      "FC1_Bias_T: (100,) float64\n",
      "FC2_Weight_T: (100, 100) float64\n",
      "FC2_Bias_T: (100,) float64\n",
      "FC3_Weight_T: (10, 100) float64\n",
      "FC3_Bias_T: (10,) float64\n"
     ]
    }
   ],
   "source": [
    "# Returns the weights and biases as a dictionary\n",
    "def readModelParam(db_path, table_names):\n",
    "    model_params = {}\n",
    "    for name in table_names:\n",
    "        # read the matrix as a list of tuples\n",
    "        mat = readMatrixTable(db_path, name)\n",
    "        # Check if it is a matrix or a vector\n",
    "        if len(mat)==1: is_vector = True\n",
    "        else: is_vector = False\n",
    "        # convert to numpy array\n",
    "        if is_vector: mat = np.array(mat[0])    # make a 1D array for vectors\n",
    "        else: mat = np.array(mat)\n",
    "        # save it for returning\n",
    "        model_params[name] = mat\n",
    "    return model_params\n",
    "\n",
    "# List of table names for running loop\n",
    "ParamTable_names = [\n",
    "    Fc1w_table,\n",
    "    Fc1b_table,\n",
    "    Fc2w_table,\n",
    "    Fc2b_table,\n",
    "    Fc3w_table,\n",
    "    Fc3b_table\n",
    "]\n",
    "print('ParamTable_names:', ParamTable_names)\n",
    "\n",
    "# Read the model parameters as numpy matrix/vectors\n",
    "model_params = readModelParam(Model_path, ParamTable_names)\n",
    "for k, v in model_params.items():\n",
    "    print(f'{k}:', v.shape, v.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71155ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fc1_weight: (100, 784) float32\n",
      "fc2_weight: (100, 100) float32\n",
      "fc3_weight: (10, 100) float32\n",
      "fc1_bias: (100,) float32\n",
      "fc2_bias: (100,) float32\n",
      "fc3_bias: (10,) float32\n"
     ]
    }
   ],
   "source": [
    "# Model Parameters class\n",
    "@dataclass\n",
    "class mlp100_Params:\n",
    "    fc1_weight: np.ndarray\n",
    "    fc2_weight: np.ndarray\n",
    "    fc3_weight: np.ndarray\n",
    "    fc1_bias: np.ndarray\n",
    "    fc2_bias: np.ndarray\n",
    "    fc3_bias: np.ndarray\n",
    "        \n",
    "\n",
    "# Instantiate the model parameter class with float32 datatype\n",
    "Model_params = mlp100_Params(\n",
    "    model_params[Fc1w_table].astype(np.float32),\n",
    "    model_params[Fc2w_table].astype(np.float32),\n",
    "    model_params[Fc3w_table].astype(np.float32),\n",
    "    model_params[Fc1b_table].astype(np.float32),\n",
    "    model_params[Fc2b_table].astype(np.float32),\n",
    "    model_params[Fc3b_table].astype(np.float32)\n",
    ")\n",
    "\n",
    "# Show the parameter info\n",
    "for field in dataclasses.fields(Model_params):\n",
    "    field_value = getattr(Model_params, field.name)\n",
    "    print(field.name+':', field_value.shape, field_value.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f40ec8",
   "metadata": {},
   "source": [
    "# Verify the Model on the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0375ac2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred: 7\n",
      "('7', 7, 7, (784,))\n"
     ]
    }
   ],
   "source": [
    "# Relu on numpy array\n",
    "def npReLU(np_arr):\n",
    "    return np.maximum(0, np_arr)\n",
    "\n",
    "\n",
    "# Performs the forward inference on the mlp100 model\n",
    "# params: model parameters, an instance of mlp100_Params\n",
    "def mlp100_forward(params, feature_vec):\n",
    "    x1 = params.fc1_weight @ feature_vec + params.fc1_bias\n",
    "    fc1_out = npReLU(x1)\n",
    "    x2 = params.fc2_weight @ fc1_out + params.fc2_bias\n",
    "    fc2_out = npReLU(x2)\n",
    "    fc3_out = params.fc3_weight @ fc2_out + params.fc3_bias\n",
    "    return fc3_out\n",
    "\n",
    "# Uses the forward pass and converts the result into predicted_index\n",
    "def mlp100_predict(params, feature_vec):\n",
    "    out_vec = mlp100_forward(params, feature_vec)\n",
    "    return np.argmax(out_vec)   # return the index of the highest probable class\n",
    "\n",
    "\n",
    "# Test this model\n",
    "item = Dataset[0]\n",
    "pred = mlp100_predict(Model_params, item.feature_vec)\n",
    "print('pred:', pred)\n",
    "print(item.getItemSummary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67f7edad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "567c04dea779480badbb01136f2b3556",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 98.36%   correct_count: 9836   expected-miss: 0   total_count: 10000\n",
      "Expected:  accuracy: 98.36%   correct_count: 9836\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "# Validate the Given model on the whole dataset\n",
    "# model_params: instance of mlp100_Params\n",
    "# model_predict: a function that takes model_params and a feacture_vec to compute predicted_index\n",
    "def validateModel(model_params, model_predict):\n",
    "    expect_miss = 0      # keeps track of no. of mismatche between prediction in dataset vs model prediction\n",
    "    total_count = 0\n",
    "    correct_count = 0\n",
    "    for item in tqdm(Dataset):\n",
    "        pred_index = model_predict(model_params, item.feature_vec)\n",
    "        if pred_index != item.predicted_index: expect_miss += 1    # prediction does not match prediction in dataset\n",
    "        if pred_index == item.label_index: correct_count += 1   # prediction matched the actual label-index\n",
    "        total_count += 1\n",
    "    # Compute and print statistics\n",
    "    accuracy = (100.0 * correct_count) / total_count\n",
    "    print(f'Validation accuracy: {accuracy:.2f}%   correct_count: {correct_count}   expected-miss: {expect_miss}   total_count: {total_count}')\n",
    "    return accuracy, correct_count, expect_miss, total_count\n",
    "\n",
    "\n",
    "validateModel(Model_params, mlp100_predict)\n",
    "print(f'Expected:  accuracy: {Header_dict[\"accuracy\"]}%', '  correct_count:', Header_dict['correct_count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513e1458",
   "metadata": {},
   "source": [
    "# Define Fixed-Point Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc00454",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b2eb215f",
   "metadata": {},
   "source": [
    "# Implement Model in Fixed-Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b08450e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "97fbac1c",
   "metadata": {},
   "source": [
    "# Experiments for Fixed-Point Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec47e441",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c647a0b7",
   "metadata": {},
   "source": [
    "# Export Model and Dataset as SQLite3 DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39833208",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
