{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f9c76f8",
   "metadata": {},
   "source": [
    "# MLP-100 Numpy Model Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511fa467",
   "metadata": {},
   "source": [
    "# Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80d5e615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch version: 2.0.1\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "# We don't need GPU for this, not training\n",
    "#if torch.cuda.is_available():\n",
    "#    device = torch.device('cuda')\n",
    "#else:\n",
    "#    device = torch.device('cpu')\n",
    "\n",
    "#print('Using PyTorch version:', torch.__version__, ' Device:', device)\n",
    "print('Using PyTorch version:', torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa160fe",
   "metadata": {},
   "source": [
    "# Load and Validate torch.nn.Module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d6b8c1",
   "metadata": {},
   "source": [
    "## Define Model\n",
    "\n",
    "**NOTE:** Always copy the following cell from the training notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "854c35f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an MLP with single hiddend layer with 12 units and ReLU activation.\n",
    "class MLP100(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(MLP100, self).__init__()\n",
    "        # Save parameters\n",
    "        self.input_size = input_size\n",
    "        self.num_classes = num_classes\n",
    "        self.debug = False    # can be used to activate debugging features\n",
    "        # Define layers\n",
    "        self.fc1 = nn.Linear(input_size, 100)   # 100 hidden units\n",
    "        self.fc1_drop = nn.Dropout(0.2)         # drop-out for faster training, has no effect on inference\n",
    "        self.fc2 = nn.Linear(100, 100)          # 100 hidden units\n",
    "        self.fc2_drop = nn.Dropout(0.2)         # drop-out for faster training, has no effect on inference\n",
    "        self.fc3 = nn.Linear(100, num_classes)  # output layer\n",
    "\n",
    "    # Expects a batch of 1-D tensor\n",
    "    # Dimension of x: (batch-size, input_size)\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))   # pass through the first hidden layer\n",
    "        x = self.fc1_drop(x)      \n",
    "        x = F.relu(self.fc2(x))   # pass through the second hidden layer\n",
    "        x = self.fc2_drop(x)      \n",
    "        x = self.fc2(x)           # pass through the output layer\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec053b91",
   "metadata": {},
   "source": [
    "## Load Saved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5f9524f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 70220\n",
      "-rw-rw-r-- 1 makabir makabir 70809849 Jun 19 14:52 test_dataset.pt\n",
      "-rw-rw-r-- 1 makabir makabir   360783 Jun 19 15:25 trained_mlp100-97.91p.pt\n",
      "-rw-rw-r-- 1 makabir makabir   360783 Jun 19 15:44 trained_mlp100.pt\n",
      "-rw-rw-r-- 1 makabir makabir   360783 Jun 19 15:44 trained_mlp100-98.17p.pt\n",
      "\n",
      "dict_keys(['accuracy', 'correct_count', 'Hparam', 'state_dict'])\n",
      "Hparam: {'input_size': 784, 'num_classes': 10}\n",
      "MLP100(\n",
      "  (fc1): Linear(in_features=784, out_features=100, bias=True)\n",
      "  (fc1_drop): Dropout(p=0.2, inplace=False)\n",
      "  (fc2): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (fc2_drop): Dropout(p=0.2, inplace=False)\n",
      "  (fc3): Linear(in_features=100, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "!ls -ltr ./saved/\n",
    "print('')\n",
    "\n",
    "# Load saved model dictionary\n",
    "model_path = './saved/trained_mlp100-98.17p.pt'\n",
    "model_dict = torch.load(model_path)\n",
    "print(model_dict.keys())\n",
    "\n",
    "# Parse the values for easier use\n",
    "Accuracy = model_dict['accuracy']\n",
    "Correct_count = model_dict['correct_count']\n",
    "Hparam = model_dict['Hparam']\n",
    "model_state_dict = model_dict['state_dict']\n",
    "Model_perf = f'Model Performance:   accuracy: {Accuracy:.2f}%   correct_count: {Correct_count}'  # to be used later\n",
    "print('Hparam:', Hparam)\n",
    "\n",
    "# Instantiate the model\n",
    "model_pt = MLP100(Hparam['input_size'], Hparam['num_classes'])\n",
    "model_pt.load_state_dict(model_state_dict)\n",
    "print(model_pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2629985d",
   "metadata": {},
   "source": [
    "## Load Saved Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ddaa28e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label_dict: {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: 8, 9: 9}\n",
      "dataset_schema: (label, label_index, predicted_index, feature_length, feature_vector)\n",
      "item-> label: 7, label_index: 7, predicted_index: 7, feature_length: 784, feature_vector size: 784\n"
     ]
    }
   ],
   "source": [
    "# Prints a dataset item\n",
    "def print_dataitem(item):\n",
    "    mstr = f\"label: {item[0]}, label_index: {item[1]}, predicted_index: {item[2]}, feature_length: {item[3]},\"\n",
    "    mstr2 = f\"feature_vector size: {len(item[4])}\"\n",
    "    print(mstr, mstr2)\n",
    "\n",
    "    \n",
    "# Load the test dataset\n",
    "ds_path = './saved/test_dataset.pt'\n",
    "DS_loaded = torch.load(ds_path)\n",
    "for key in DS_loaded:\n",
    "    if key != 'dataset':\n",
    "        print(f'{key}:', DS_loaded[key])\n",
    "\n",
    "# Show an item summary\n",
    "item = DS_loaded['dataset'][0]\n",
    "print('item-> ', end='')\n",
    "print_dataitem(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f38b3c",
   "metadata": {},
   "source": [
    "## Validate The Loaded Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbfedfd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred: 7\n",
      "label: 7, label_index: 7, predicted_index: 7, feature_length: 784, feature_vector size: 784\n"
     ]
    }
   ],
   "source": [
    "# find most likely label index for each element\n",
    "def get_likely_index(tensor):\n",
    "    return tensor.argmax(dim=-1)\n",
    "\n",
    "\n",
    "# Given an item form the test_dataset, returns an example for predict() function\n",
    "def make_example(data_item):\n",
    "    feature = torch.tensor(data_item[4])\n",
    "    return feature\n",
    "\n",
    "\n",
    "# test prediction from dataset item.\n",
    "# ptmodel: set it to True for the PyTorch model\n",
    "def predict(example, model=None, ptmodel=False):  # example: feature_vector\n",
    "    if ptmodel: model.eval()    # set the pytorch model to evaluation mode\n",
    "    # Use the model to predict the label of the image\n",
    "    feature = example\n",
    "    output = model(feature.unsqueeze(0))\n",
    "    pred = get_likely_index(output)[0]   # indexing to get the prediction from batch\n",
    "    return pred.item()\n",
    "\n",
    "\n",
    "# Test predict()\n",
    "item = DS_loaded['dataset'][0]\n",
    "example = make_example(item)\n",
    "pred = predict(example, model=model_pt, ptmodel=True)\n",
    "print('pred:',pred)\n",
    "print_dataitem(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be7992f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbdb29eb1ea44eab8f15a1a1e0455d0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 98.17%   correct_count: 9817   expected-miss: 323   total_count: 10000\n",
      "Expected Model Performance:   accuracy: 98.17%   correct_count: 9817\n"
     ]
    }
   ],
   "source": [
    "# Validate the Given model on the whole dataset\n",
    "# ptmodel: set it to True for the PyTorch model\n",
    "def validateMode(model=None, ptmodel=False):\n",
    "    dataset = DS_loaded['dataset']\n",
    "    expect_miss = 0      # keeps track of no. of mismatche between prediction in dataset vs model prediction\n",
    "    total_count = 0\n",
    "    correct_count = 0\n",
    "    for item in tqdm(dataset):\n",
    "        lbl, lbl_index, pred_index, *_ = item\n",
    "        example = make_example(item)\n",
    "        pred = predict(example, model=model, ptmodel=ptmodel)\n",
    "        if pred != pred_index: expect_miss += 1    # prediction does not match prediction in dataset\n",
    "        if pred == lbl_index: correct_count += 1   # prediction matched the actual label-index\n",
    "        total_count += 1\n",
    "    # Compute and print statistics\n",
    "    accuracy = (100.0 * correct_count) / total_count\n",
    "    print(f'Validation accuracy: {accuracy:.2f}%   correct_count: {correct_count}   expected-miss: {expect_miss}   total_count: {total_count}')\n",
    "    return accuracy, correct_count, expect_miss, total_count\n",
    "\n",
    "            \n",
    "# Validate the loaded model\n",
    "validateMode(model_pt, ptmodel=True)\n",
    "print('Expected', Model_perf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4ff01f",
   "metadata": {},
   "source": [
    "# Implementation Using torch.tensor Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472e2a65",
   "metadata": {},
   "source": [
    "# Implement Using Numpy Matrixing Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5e7ac7",
   "metadata": {},
   "source": [
    "# Export Numpy Model & Dataset as sqlite3 DB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac6673f",
   "metadata": {},
   "source": [
    "# Import Saved Model and Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0ef000",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
