{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1b5a119",
   "metadata": {},
   "source": [
    "# Fixed Point Precision Study on MLP-100\n",
    "\n",
    "This note book is the final stage of the model preparation for benchmarking. The next stage after this notebook is to simply implement the model in C using the knowledge gained from this notebook.\n",
    "The fixed-point operations defined here tries to simulate the computations performed in SPAR. This might change over-time.\n",
    "\n",
    "**NOTE:**\n",
    "The programs/code-snippets in this notebook follows C-like interfaces on purpose.\n",
    "This is done so that, these code can be easily translated into C for the next stage of study.\n",
    "\n",
    "**Goals:**\n",
    "- Load the Model and Dataset from the SQLite3 databases.\n",
    "- Validate numpy model on the dataset.\n",
    "- Define Fixed-Point methods.\n",
    "- Implement model in fixed-point.\n",
    "- Experiment with Fixed-Point precisions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4738ee",
   "metadata": {},
   "source": [
    "# Load Floating-Point Model Parameters and Datset\n",
    "\n",
    "Here, the model and the dataset exported by the Numpy model extraction notebook is loaded and verified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8e4e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the cache and import sqlite3 utilities\n",
    "!rm -rf __pycache__/\n",
    "from utilsqlite3 import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf40c7c",
   "metadata": {},
   "source": [
    "## Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c60127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and check the dataset table\n",
    "Dataset_path = './saved/mnist_test_data-94.00p.s3db'\n",
    "\n",
    "table_names = getTableNames(Dataset_path)\n",
    "print('table_names:', table_names)\n",
    "\n",
    "# Read the header table\n",
    "header_records =  getRecords(Dataset_path, 'Header')\n",
    "header_dict = {}\n",
    "print('')\n",
    "for r in header_records: \n",
    "    print(r[1:3])\n",
    "    header_dict[r[1]] = r[2]\n",
    "    \n",
    "# Get the table names\n",
    "Data_table = header_dict['dataset.table']\n",
    "Feature_table = header_dict['features.table']\n",
    "Label_table = header_dict['labels.table']\n",
    "print('')\n",
    "print('Data_table:', Data_table)\n",
    "print('Feature_table:', Feature_table)\n",
    "print('Label_table:', Label_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c7b0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the label_to_index dictionary\n",
    "labels_records = getRecords(Dataset_path, Label_table)\n",
    "print('labels_records:', labels_records)\n",
    "\n",
    "Label_to_index = {label:index for (index, label) in labels_records}\n",
    "Index_to_label = {index:label for (index, label) in labels_records}\n",
    "print('Label_to_index:', Label_to_index)\n",
    "print('Index_to_label:', Index_to_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552007f6",
   "metadata": {},
   "source": [
    "### Build the Dataset Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec1a0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import dataclasses\n",
    "from dataclasses import dataclass\n",
    "from typing import List\n",
    "\n",
    "\n",
    "# Dataset item class\n",
    "@dataclass\n",
    "class DataItem:\n",
    "    label: str\n",
    "    label_index: int\n",
    "    predicted_index: int\n",
    "    feature_vec: List[np.float32]\n",
    "        \n",
    "    def getItemSummary(self):\n",
    "        return str((self.label, self.label_index, self.predicted_index, self.feature_vec.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73c1f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the features and data-item records then merge them\n",
    "# Make the feature_id:feature_vec map\n",
    "feat_records = getRecords(Dataset_path, Feature_table)\n",
    "featid_map = {}\n",
    "for r in feat_records:\n",
    "    feat_id = r[0]       # first column is the feature ID\n",
    "    feat_vec = r[1:]\n",
    "    featid_map[feat_id]  = feat_vec\n",
    "\n",
    "    \n",
    "# Read the data-items and put them in DataItem array\n",
    "Dataset = []\n",
    "data_records = getRecords(Dataset_path, Data_table)\n",
    "data_schema = getColNames(Dataset_path, Data_table)\n",
    "print('data_schema:', data_schema)\n",
    "\n",
    "for r in data_records:\n",
    "    label = r[1]\n",
    "    label_index = r[2]\n",
    "    pred_index = r[3]\n",
    "    feat_id = r[4]\n",
    "    feat_vec = np.array(featid_map[feat_id], dtype=np.float32)\n",
    "    item = DataItem(label, label_index, pred_index, feat_vec)\n",
    "    Dataset.append(item)\n",
    "\n",
    "item = Dataset[0]\n",
    "print('Dataset:', len(Dataset))\n",
    "print('item:', item.getItemSummary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b859dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete names to avoid confusion later\n",
    "del table_names, r, labels_records, header_records, header_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157b0fb7",
   "metadata": {},
   "source": [
    "## Load the Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c93b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and check the model parameters table\n",
    "Model_path = './saved/trained-mlp12-94.00p.s3db'\n",
    "\n",
    "table_names = getTableNames(Model_path)\n",
    "print('table_names:', table_names)\n",
    "\n",
    "# Read the header table\n",
    "header_records =  getRecords(Model_path, 'Header')\n",
    "Header_dict = {}\n",
    "print('')\n",
    "for r in header_records: \n",
    "    print(r[1:3])\n",
    "    Header_dict[r[1]] = r[2]\n",
    "\n",
    "\n",
    "# Get the table names for later use\n",
    "Fc1w_table = Header_dict['fc1.weight.table']\n",
    "Fc1b_table = Header_dict['fc1.bias.table']\n",
    "Fc2w_table = Header_dict['fc2.weight.table']\n",
    "Fc2b_table = Header_dict['fc2.bias.table']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6148e286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns a table saved using createMatrixTable as a list of tuples\n",
    "def readMatrixTable(db_path, table_name):\n",
    "    # read the records\n",
    "    rec_list = getRecords(db_path, table_name)\n",
    "    # build the matrix\n",
    "    rec_list.sort()         # sort by row_no (first column)\n",
    "    matrix = []\n",
    "    for rec in rec_list:\n",
    "        matrix.append(rec[1:])  # stripe off the row_no columns\n",
    "    return matrix\n",
    "\n",
    "\n",
    "# test this functions\n",
    "mat1 = np.array(readMatrixTable(Model_path, Fc1w_table))\n",
    "mat1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b886ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns the weights and biases as a dictionary\n",
    "def readModelParams(db_path, table_names):\n",
    "    model_params = {}\n",
    "    for name in table_names:\n",
    "        # read the matrix as a list of tuples\n",
    "        mat = readMatrixTable(db_path, name)\n",
    "        # Check if it is a matrix or a vector\n",
    "        if len(mat)==1: is_vector = True\n",
    "        else: is_vector = False\n",
    "        # convert to numpy array\n",
    "        if is_vector: mat = np.array(mat[0])    # make a 1D array for vectors\n",
    "        else: mat = np.array(mat)\n",
    "        # save it for returning\n",
    "        model_params[name] = mat\n",
    "    return model_params\n",
    "\n",
    "\n",
    "# List of table names for running loop\n",
    "ParamTable_names = [\n",
    "    Fc1w_table,\n",
    "    Fc1b_table,\n",
    "    Fc2w_table,\n",
    "    Fc2b_table,\n",
    "]\n",
    "print('ParamTable_names:', ParamTable_names)\n",
    "\n",
    "# Read the model parameters as numpy matrix/vectors\n",
    "model_params = readModelParams(Model_path, ParamTable_names)\n",
    "for k, v in model_params.items():\n",
    "    print(f'{k}:', v.shape, v.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4f6066",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Parameters class\n",
    "@dataclass\n",
    "class mlp12_Params:\n",
    "    fc1_weight: np.ndarray\n",
    "    fc2_weight: np.ndarray\n",
    "    fc1_bias: np.ndarray\n",
    "    fc2_bias: np.ndarray\n",
    "        \n",
    "\n",
    "# Instantiate the model parameter class with float32 datatype\n",
    "Model_params = mlp12_Params(\n",
    "    model_params[Fc1w_table].astype(np.float32),\n",
    "    model_params[Fc2w_table].astype(np.float32),\n",
    "    model_params[Fc1b_table].astype(np.float32),\n",
    "    model_params[Fc2b_table].astype(np.float32),\n",
    ")\n",
    "\n",
    "# Show the parameter info\n",
    "for field in dataclasses.fields(Model_params):\n",
    "    field_value = getattr(Model_params, field.name)\n",
    "    print(field.name+':', field_value.shape, field_value.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e02d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "del feat_id, feat_records, feat_vec, featid_map, field, field_value\n",
    "del item, k, label, label_index, mat1, pred_index, r, v, table_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6483cb",
   "metadata": {},
   "source": [
    "# Verify Model on the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c744a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relu on numpy array\n",
    "def npReLU(np_arr):\n",
    "    return np.maximum(0, np_arr)\n",
    "\n",
    "\n",
    "# Performs the forward inference on the mlp12 model\n",
    "# params: model parameters, an instance of mlp12_Params\n",
    "def mlp12_forward(params, feature_vec):\n",
    "    x1 = params.fc1_weight @ feature_vec + params.fc1_bias\n",
    "    fc1_out = npReLU(x1)\n",
    "    fc2_out = params.fc2_weight @ fc1_out + params.fc2_bias\n",
    "    return fc2_out\n",
    "\n",
    "\n",
    "# Uses the forward pass and converts the result into predicted_index\n",
    "def mlp12_predict(params, feature_vec):\n",
    "    out_vec = mlp12_forward(params, feature_vec)\n",
    "    return np.argmax(out_vec)   # return the index of the highest probable class\n",
    "\n",
    "\n",
    "# Test this model\n",
    "item = Dataset[0]\n",
    "pred = mlp12_predict(Model_params, item.feature_vec)\n",
    "print('pred:', pred)\n",
    "print(item.getItemSummary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0fa422",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "# Validate the Given model on the whole dataset\n",
    "# model_params: instance of mlp12_Params\n",
    "# model_predict: a function that takes model_params and a feacture_vec to compute predicted_index\n",
    "def validateModel(model_params, model_predict):\n",
    "    expect_miss = 0      # keeps track of no. of mismatches between prediction in dataset vs model prediction\n",
    "    total_count = 0\n",
    "    correct_count = 0\n",
    "    for item in tqdm(Dataset):\n",
    "        pred_index = model_predict(model_params, item.feature_vec)\n",
    "        if pred_index != item.predicted_index: expect_miss += 1    # prediction does not match prediction in dataset\n",
    "        if pred_index == item.label_index: correct_count += 1   # prediction matched the actual label-index\n",
    "        total_count += 1\n",
    "    # Compute and print statistics\n",
    "    accuracy = (100.0 * correct_count) / total_count\n",
    "    print(f'Validation accuracy: {accuracy:.2f}%   correct_count: {correct_count}   expected-miss: {expect_miss}   total_count: {total_count}')\n",
    "    return accuracy, correct_count, expect_miss, total_count\n",
    "\n",
    "\n",
    "validateModel(Model_params, mlp12_predict)\n",
    "print(f'Expected:  accuracy: {Header_dict[\"accuracy\"]}%', '  correct_count:', Header_dict['correct_count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa06a60a",
   "metadata": {},
   "source": [
    "# Define Fixed Point Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12026965",
   "metadata": {},
   "source": [
    "## Data Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289e3a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the cache before importing\n",
    "!rm -rf __pycache__/\n",
    "from AK_FixedPoint import *\n",
    "\n",
    "# Run Unit tests to make sure everything is okay\n",
    "!python3 unittest_fxp.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18624d09",
   "metadata": {},
   "source": [
    "## Math Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6745e137",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run unit tests to make sure everything is okay\n",
    "!python3 unittest_fxp_math.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e174e1",
   "metadata": {},
   "source": [
    "## Matrix Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a54070",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import inf as INF\n",
    "\n",
    "\n",
    "# Performs matrix-vector multiplication and keeps track of error.\n",
    "# status_obj: instance of fxp_Status to get status back\n",
    "# Returns the output vector and a tupel with intermediate results for debugging: resutl, (...)\n",
    "def fxp_matmul_mv(fxp_mat, fxp_vec, status_obj=None, debug=False):\n",
    "    # Make sure all assumptions are met\n",
    "    assert len(fxp_mat._data.shape) == 2, \"fxp_mat must be built from a 2D Numpy array\"\n",
    "    assert len(fxp_vec._data.shape) == 1, \"fxp_mat must be built from a 1D Numpy array\"\n",
    "    assert fxp_mat._data.shape[1] == fxp_vec._data.shape[0], \"Matrix column count not equal vector length\"\n",
    "    \n",
    "    # Get the data-type parameters\n",
    "    t_width = fxp_vec._total_width\n",
    "    f_width = fxp_vec._frac_width\n",
    "    compute_status = True if status_obj != None else False\n",
    "    \n",
    "    # multiply row-wise\n",
    "    prod_np = (fxp_mat._data * fxp_vec._data)   # multiplying raw values\n",
    "    # compute error status for multiplying into 2x wider result (less likely to have errors in this step)\n",
    "    fxp_prod = fxp_makeWider(fxp_mat, 2)  # build 2x wider fxp object\n",
    "    fxp_prod._data = prod_np              # copy the raw product values\n",
    "    prod_stat = fxp_fitData(fxp_prod, compute_status)   # now fit within this precision\n",
    "    if compute_status: \n",
    "        if debug: print('prod_stat:', prod_stat)\n",
    "        fxp_accumulateStatus(status_obj, prod_stat)  # record the multiplication errors\n",
    "        \n",
    "    # Now scale down to original precision before accumulation; record error status\n",
    "    prod_np_down = prod_np >> f_width       # discard lower fraction bits\n",
    "    fxp_prod_down = fxp_makeSame(fxp_mat)   # fxp object with original precision\n",
    "    fxp_prod_down._data = prod_np_down\n",
    "    prod_down_stat = fxp_fitData(fxp_prod_down, compute_status)\n",
    "    if compute_status: \n",
    "        if debug: print('prod_down_stat:', prod_down_stat)\n",
    "        fxp_accumulateStatus(status_obj, prod_down_stat)  # accumulate the scaling errors\n",
    "        \n",
    "    # accumulate along rows; record error status\n",
    "    accum_np = np.sum(fxp_prod_down._data, axis=1)\n",
    "    fxp_accum = fxp_makeSame(fxp_vec)\n",
    "    fxp_accum._data = accum_np\n",
    "    accum_stat = fxp_fitData(fxp_accum, compute_status)\n",
    "    if compute_status: \n",
    "        if debug: print('accum_stat:', accum_stat)\n",
    "        fxp_accumulateStatus(status_obj, accum_stat)  # accumulate the scaling errors\n",
    "    return fxp_accum, (prod_np, fxp_prod, prod_np_down, fxp_prod_down, accum_np, fxp_accum)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec84b34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "mat_inp = [\n",
    "    [1, 2, 3, 4],\n",
    "    [2, 5, 7, 2],\n",
    "    [9, 3, 5, 0],\n",
    "]\n",
    "vec_inp = [4, 8, 1, 2]\n",
    "mat_np = np.array(mat_inp)\n",
    "vec_np = np.array(vec_inp)\n",
    "res_np = mat_np @ vec_np\n",
    "print(res_np)\n",
    "\n",
    "total_width = 10\n",
    "frac_width = 4\n",
    "stat = fxp_Status(False, 0, -INF, INF, -INF, INF)\n",
    "fxp_mat_inp, _ = fxp_ctor(total_width, frac_width, mat_np)\n",
    "fxp_vec_inp, _ = fxp_ctor(total_width, frac_width, vec_np)\n",
    "fxp_result, dbg = fxp_matmul_mv(fxp_mat_inp, fxp_vec_inp, stat, debug=True)\n",
    "\n",
    "\n",
    "print('Overall status:', stat)\n",
    "\n",
    "print('')\n",
    "fxp_printInfo(fxp_result)\n",
    "fxp_printValue(fxp_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4902196c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the intermediate results\n",
    "prod_np, fxp_prod, prod_np_down, fxp_prod_down, accum_np, fxp_accum = dbg\n",
    "print(mat_np * vec_np)\n",
    "print('')\n",
    "\n",
    "print(prod_np >> (2*frac_width))\n",
    "\n",
    "print('')\n",
    "fxp_printInfo(fxp_prod)\n",
    "fxp_printValue(fxp_prod)\n",
    "\n",
    "print('')\n",
    "fxp_printInfo(fxp_prod_down)\n",
    "fxp_printValue(fxp_prod_down)\n",
    "\n",
    "\n",
    "print('')\n",
    "fxp_printInfo(fxp_accum)\n",
    "fxp_printValue(fxp_accum)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ec640f",
   "metadata": {},
   "outputs": [],
   "source": [
    "del accum_np, data_records, data_schema, frac_width, header_records\n",
    "del item, mat_inp, mat_np, model_params, pred, prod_np, prod_np_down\n",
    "del res_np, stat, total_width, vec_inp, vec_np, "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9646452f",
   "metadata": {},
   "source": [
    "# Implement Model in Fixed-Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11cc871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Model Parameters to fixed point\n",
    "Fxp_total_width = 30   # don't use 32\n",
    "Fxp_frac_width = 15\n",
    "\n",
    "def convertParamsFxp(params, total_width, frac_width):\n",
    "    fc1w_fxp, stat = fxp_ctor(total_width, frac_width, params.fc1_weight)\n",
    "    assert stat.overflow==False, \"Overflow\"\n",
    "    fc2w_fxp, stat = fxp_ctor(total_width, frac_width, params.fc2_weight)\n",
    "    assert stat.overflow==False, \"Overflow\"\n",
    "\n",
    "    fc1b_fxp, stat = fxp_ctor(total_width, frac_width, params.fc1_bias)\n",
    "    assert stat.overflow==False, \"Overflow\"\n",
    "    fc2b_fxp, stat = fxp_ctor(total_width, frac_width, params.fc2_bias)\n",
    "    assert stat.overflow==False, \"Overflow\"\n",
    "    \n",
    "    fxp_params = mlp12_Params(fc1w_fxp, fc2w_fxp,  fc1b_fxp, fc2b_fxp)\n",
    "    return fxp_params\n",
    "\n",
    "\n",
    "Fxp_model_param = convertParamsFxp(Model_params, Fxp_total_width, Fxp_frac_width)\n",
    "fxp_printInfo(Fxp_model_param.fc1_weight)\n",
    "Fxp_model_param.fc1_weight._data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e07f8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relu on fxp\n",
    "def fxpReLU(fxp_num):\n",
    "    relu_out = np.maximum(0, fxp_num._data)\n",
    "    fxp_ret = fxp_makeSame(fxp_num)\n",
    "    fxp_ret._data = relu_out\n",
    "    stat = fxp_fitData(fxp_ret, True)   # is not necessary for Relu\n",
    "    assert stat.overflow==False, \"Unexpected overflow in ReLU\"\n",
    "    return fxp_ret\n",
    "\n",
    "\n",
    "# Test fxpReLU()\n",
    "inp_vec = [0, -1, 2, 4, -2]\n",
    "out_vec = [0,  0, 2, 4,  0]\n",
    "fxp_test, _ = fxp_ctor(Fxp_total_width, Fxp_frac_width, inp_vec)\n",
    "relu_out = fxpReLU(fxp_test)\n",
    "fxp_printValue(relu_out)\n",
    "result = fxp_getAsFloat(relu_out) == out_vec\n",
    "assert result.all(), \"Problem with fxpReLU()\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058c28b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performs the forward inference on the mlp12 model\n",
    "# params: model parameters, an instance of mlp12_Params with fixed-point numbers\n",
    "def mlp12_forward_fxp(params, feature_vec, debug=False):\n",
    "    # Make status objects\n",
    "    stat = fxp_Status(False, 0, -INF, INF, -INF, INF)\n",
    "    temp_stat = fxp_Status(0,0,0,0,0,0)\n",
    "    # Layer-1\n",
    "    #fxp_printInfo(params.fc1_weight)\n",
    "    #fxp_printInfo(feature_vec)\n",
    "    x1, _ = fxp_matmul_mv(params.fc1_weight, feature_vec, stat)\n",
    "    if debug: print(stat)\n",
    "    x1 = fxp_add(x1, params.fc1_bias, temp_stat)\n",
    "    fxp_accumulateStatus(stat, temp_stat)\n",
    "    if debug: print(stat)\n",
    "    fc1_out = fxpReLU(x1)\n",
    "    \n",
    "    # output layer\n",
    "    x2, _ = fxp_matmul_mv(params.fc2_weight, fc1_out, stat)\n",
    "    if debug: print(stat)\n",
    "    fc2_out = fxp_add(x2, params.fc2_bias, temp_stat)\n",
    "    fxp_accumulateStatus(stat, temp_stat)\n",
    "    if debug: print(stat)\n",
    "    return fc2_out, stat\n",
    "\n",
    "\n",
    "# Uses the forward pass and converts the result into predicted_index\n",
    "def mlp12_predict_fxp(params, feature_vec, debug=False):\n",
    "    out_vec, stat = mlp12_forward_fxp(params, feature_vec, debug=debug)\n",
    "    return np.argmax(out_vec._data), stat   # return the index of the highest probable class and error status\n",
    "\n",
    "\n",
    "# Test this model\n",
    "item = Dataset[0]\n",
    "feat_vec, stat = fxp_ctor(Fxp_total_width, Fxp_frac_width, item.feature_vec)\n",
    "pred, status = mlp12_predict_fxp(Fxp_model_param, feat_vec , debug=True)\n",
    "print('pred:', pred)\n",
    "print(item.getItemSummary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18750faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dataset into fixed-point\n",
    "def convertDatasetFxp(dataset, total_width, frac_width):\n",
    "    fxp_dataset = []\n",
    "    for item in dataset:\n",
    "        fxp_feat_vec, stat = fxp_ctor(total_width, frac_width, item.feature_vec)\n",
    "        fxp_item = DataItem(item.label, item.label_index, item.predicted_index, fxp_feat_vec)\n",
    "        fxp_dataset.append(fxp_item)\n",
    "    return fxp_dataset\n",
    "\n",
    "\n",
    "# Test\n",
    "Fxp_Dataset = convertDatasetFxp(Dataset, Fxp_total_width, Fxp_frac_width)\n",
    "print('Fxp_Dataset:', len(Fxp_Dataset))\n",
    "item = Fxp_Dataset[0]\n",
    "pred, status = mlp12_predict_fxp(Fxp_model_param, item.feature_vec , debug=False)\n",
    "print('pred:', pred, '   Expected:', item.predicted_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde20000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate the Fixed-point model on the whole dataset\n",
    "# model_params: instance of mlp12_Params\n",
    "# model_predict: a function that takes model_params and a feacture_vec to compute predicted_index\n",
    "def validateModelFxp(fxp_dataset, model_params, model_predict):\n",
    "    expect_miss = 0      # keeps track of no. of mismatche between prediction in dataset vs model prediction\n",
    "    total_count = 0\n",
    "    correct_count = 0\n",
    "    stat_list = []\n",
    "    for item in tqdm(fxp_dataset):\n",
    "        pred_index, stat = model_predict(model_params, item.feature_vec, debug=False)\n",
    "        if stat.overflow: stat_list.append(stat)\n",
    "        if pred_index != item.predicted_index: expect_miss += 1    # prediction does not match prediction in dataset\n",
    "        if pred_index == item.label_index: correct_count += 1   # prediction matched the actual label-index\n",
    "        total_count += 1\n",
    "    # Compute and print statistics\n",
    "    accuracy = (100.0 * correct_count) / total_count\n",
    "    print(f'Validation accuracy: {accuracy:.2f}%   correct_count: {correct_count}   expected-miss: {expect_miss}   total_count: {total_count}')\n",
    "    print(f'Item overflow count: {len(stat_list)}')\n",
    "    return accuracy, correct_count, expect_miss, total_count, stat_list\n",
    "\n",
    "\n",
    "validateModelFxp(Fxp_Dataset, Fxp_model_param, mlp12_predict_fxp)\n",
    "print(f'Expected:  accuracy: {Header_dict[\"accuracy\"]}%', '  correct_count:', Header_dict['correct_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a330b216",
   "metadata": {},
   "outputs": [],
   "source": [
    "del status, stat, result, relu_out, pred, Fxp_Dataset\n",
    "del out_vec, item, inp_vec, fxp_vec_inp, dbg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231ac72f",
   "metadata": {},
   "source": [
    "# Experiment with Fixed-Point Precisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead33efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up precision to convert model and dataset\n",
    "trial_int_width = 15\n",
    "trial_frac_width = 15\n",
    "trial_total_width = trial_frac_width + trial_int_width\n",
    "\n",
    "fxp_model_param = convertParamsFxp(Model_params, trial_total_width, trial_frac_width)\n",
    "fxp_printInfo(fxp_model_param.fc1_weight)\n",
    "\n",
    "print('')\n",
    "fxp_dataset = convertDatasetFxp(Dataset, trial_total_width, trial_frac_width)\n",
    "print('fxp_Dataset:', len(fxp_dataset))\n",
    "item = fxp_dataset[0]\n",
    "fxp_printInfo(item.feature_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20f333a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run validation, collect result, then tabulate\n",
    "validation_result = validateModelFxp(fxp_dataset, fxp_model_param, mlp12_predict_fxp)\n",
    "print(f'Expected:  accuracy: {Header_dict[\"accuracy\"]}%', '  correct_count:', Header_dict['correct_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9733f3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print results for Tabulation\n",
    "accuracy, correct_count, expect_miss, total_count, stat_list = validation_result\n",
    "overflow_item_count = len(stat_list)\n",
    "overflow_count = 0\n",
    "for stat in stat_list: overflow_count += stat.overflow_count\n",
    "\n",
    "#row_header = \"total_width,  frac_width,  int_width,  accuracy%,  total-items,  correct_count,  prediction-mismatch,  overflow-item-count,  overflow-count\"\n",
    "row_template = \"{total_width}\\t{int_width}\\t{frac_width}\\t{accuracy}\\t{total_items}\\t{correct_count}\\t{prediction_mismatch}\\t{overflow_item_count}\\t{overflow_count}\"\n",
    "\n",
    "print(row_template.replace('\\t', ' '))\n",
    "print(row_template.format(\n",
    "    total_width=trial_total_width, frac_width=trial_frac_width, int_width=trial_int_width,\n",
    "    accuracy=accuracy, \n",
    "    total_items=len(fxp_dataset), correct_count=correct_count, prediction_mismatch=expect_miss, \n",
    "    overflow_item_count=overflow_item_count, overflow_count=overflow_count\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080f1c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the individual item overflow status if needed\n",
    "max_overflow_count = -1\n",
    "for stat in stat_list: \n",
    "    print(stat)\n",
    "    max_overflow_count = max(max_overflow_count, stat.overflow_count)\n",
    "\n",
    "avg_overflow_count = overflow_count / len(stat_list)\n",
    "print('')\n",
    "print('max:', max_overflow_count,  '  avg_overflow_count:', avg_overflow_count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
