{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c232c11",
   "metadata": {},
   "source": [
    "# LSTM-250 Numpy Model Extraction\n",
    "\n",
    "## Goals\n",
    "\n",
    "- Loads Dataset and Model from training notebook and validates.\n",
    "- Translates the model into Numpy operations and validates.\n",
    "- Dataset updated with the accuracy from the Numpy model.\n",
    "- Model and dataset exported as sqlite3 database for implementation in C.\n",
    "\n",
    "**NOTE:** The dataset exported by the training notebook may have incorrect predicted index due to several iterations of model training and not updating the dataset. We'll re-run the predictions here and update the predicted index in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ff9b34",
   "metadata": {},
   "source": [
    "# Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d25674",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import IPython.display as ipd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "#if torch.cuda.is_available():\n",
    "#    device = torch.device('cuda')\n",
    "#else:\n",
    "#    device = torch.device('cpu')\n",
    "\n",
    "#print('Using PyTorch version:', torch.__version__, ' Device:', device)\n",
    "print('Using PyTorch version:', torch.__version__)\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b34417",
   "metadata": {},
   "source": [
    "# Load and Validate torch.nn.Module Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b91ca1",
   "metadata": {},
   "source": [
    "## Define Model\n",
    "\n",
    "**NOTE:** Always copy the following cell from the training notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77891893",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.utils.rnn as rnn_utils\n",
    "\n",
    "\n",
    "# LSTM model definition\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.num_classes = num_classes\n",
    "        self.debug = False    # Set it to true to print debug info\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=0.2)\n",
    "        #self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "    \n",
    "    # Expects a padded_sequence of batched input and the lengths of the sequences\n",
    "    def forward(self, pad_seq, lengths):        \n",
    "        if self.debug: print('DEBUG START: LSTM model ---')\n",
    "\n",
    "        # Extract batch size for initialization of hidden state\n",
    "        batch_size = len(pad_seq)\n",
    "            \n",
    "        # Set initial hidden and cell states\n",
    "        h0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device) \n",
    "        c0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device)\n",
    "        \n",
    "        # Convert padded sequence to variable length packed sequence for LSTM\n",
    "        packed_seq = rnn_utils.pack_padded_sequence(pad_seq, lengths, enforce_sorted=False, batch_first=True)\n",
    "        \n",
    "        # Forward propagate LSTM, returns a packed sequence\n",
    "        out_packed, _ = self.lstm(packed_seq, (h0, c0))\n",
    "        \n",
    "        # Extract final hidden states of each sequence for the output layer\n",
    "        out_pad, out_lens = rnn_utils.pad_packed_sequence(out_packed, batch_first=True)\n",
    "        out_indx = out_lens - 1   # indices of the last valid hidden state in the padded sequence\n",
    "        last_hidden = out_pad[range(batch_size), out_indx].contiguous()  # select the last valid state in each sequence, and make them contiguous for efficiency\n",
    "        self.lstm_outpad = out_pad   # Save for later testing\n",
    "                \n",
    "        if self.debug:\n",
    "            print('last_hidden size:', last_hidden.size())\n",
    "            print('last_hidden:\\n', last_hidden)\n",
    "        \n",
    "        # Decode the hidden state of the last time step only (for whole batch)\n",
    "        out = self.fc(last_hidden)\n",
    "        if self.debug: print('DEBUG END: LSTM model ---')\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df993cfa",
   "metadata": {},
   "source": [
    "## Load Saved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45136248",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -ltrh ./session/\n",
    "print('')\n",
    "\n",
    "# Load saved model dictionary\n",
    "model_path = './session/trained-lstm250.pt'\n",
    "model_dict = torch.load(model_path)\n",
    "print(model_dict.keys())\n",
    "\n",
    "\n",
    "# Parse the values for easier use\n",
    "Accuracy = model_dict['accuracy']\n",
    "Correct_count = model_dict['correct_count']\n",
    "Index_to_label = model_dict['index_to_label']\n",
    "Label_to_index = {label:index for index, label in Index_to_label.items()}\n",
    "Hparam = model_dict['Hparam']\n",
    "Model_state_dict = model_dict['state_dict']\n",
    "Model_perf = f'Model Performance:   accuracy: {Accuracy:.2f}%   correct_count: {Correct_count}'  # to be used later\n",
    "print('Hparam:', Hparam)\n",
    "print('Model_perf:', Model_perf)\n",
    "\n",
    "\n",
    "# move all weights to cpu\n",
    "for key in Model_state_dict: \n",
    "    Model_state_dict[key] = Model_state_dict[key].to('cpu')\n",
    "    \n",
    "    \n",
    "# Instantiate the model\n",
    "model_pt = LSTM(Hparam['input_size'], Hparam['hidden_size'], Hparam['num_layers'], Hparam['num_classes'])\n",
    "model_pt.load_state_dict(Model_state_dict)\n",
    "model_pt.to('cpu')\n",
    "model_pt.eval()     # we are always evaluating here\n",
    "print(model_pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117a338a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete names to avoid confusions later\n",
    "del model_path, model_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ae530e",
   "metadata": {},
   "source": [
    "## Load Saved Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18dac7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prints information about dataset item\n",
    "def print_dataItem(item):\n",
    "    mstr = f\"label: {item[0]}, label_index: {item[1]}, predicted_index: {item[2]}, sequence_length: {item[3]},\"\n",
    "    mstr2 = f\"\\nfeature_sequence shape: {item[4].shape}, feature_seq type: {type(item[4])}\"\n",
    "    print(mstr, mstr2)\n",
    "\n",
    "    \n",
    "# Load the test dataset\n",
    "ds_path = \"./session/test-export-ds.pt\"\n",
    "DS_loaded = torch.load(ds_path)\n",
    "print(DS_loaded.keys())\n",
    "print('DS_loaded len:', len(DS_loaded['dataset']))\n",
    "print('schema:', DS_loaded['dataset_schema'])\n",
    "\n",
    "\n",
    "# Make sure the label-to-index dictionary matches the one in the model\n",
    "for key in DS_loaded['label_dict']:\n",
    "    assert DS_loaded['label_dict'][key] == Label_to_index[key], 'Dataset and Model Label-to-index are different'\n",
    "print('INFO: Dataset and Model label-to-index matched')\n",
    "\n",
    "\n",
    "# show an item information\n",
    "DataItems = DS_loaded['dataset']\n",
    "item = DataItems[0]\n",
    "print_dataItem(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2264ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete names to avoid confusions later\n",
    "del ds_path, key, item"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c2a2eb",
   "metadata": {},
   "source": [
    "## Validate Loaded Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba57ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padding is needed to make the batch <tensor> from <list> of variable length sequences\n",
    "# The padding values are not passed to the LSTM during trainig/testing\n",
    "def pad_sequence_lstm(batch):\n",
    "    # Make all tensor in a batch the same length by padding with zeros\n",
    "    batch = rnn_utils.pad_sequence(batch, batch_first=True, padding_value=0.)\n",
    "    return batch\n",
    "\n",
    "\n",
    "# Gets the list of audio and labels as batch then\n",
    "# converts them into sequence of features for the model.\n",
    "# Adds padding to build the batch tensor\n",
    "def collate_fn_lstm(batch):\n",
    "    tensors, targets, lengths = [], [], []   # lengths is needed for pack_padded_sequence  in LSTM.forward()\n",
    "\n",
    "    # Gather in lists, and encode labels as indices\n",
    "    for item in batch:\n",
    "        label, feat_seq = item\n",
    "        feat_seq_tensor = torch.from_numpy(feat_seq)\n",
    "        tensors += [feat_seq_tensor]\n",
    "        targets += [Label_to_index[label]]\n",
    "        lengths.append(feat_seq_tensor.size()[0])\n",
    "\n",
    "    # Group the list of tensors into a batched tensor\n",
    "    tensors = pad_sequence_lstm(tensors)\n",
    "    targets = torch.tensor(targets)\n",
    "    lengths = torch.tensor(lengths)\n",
    "    return tensors, targets, lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f712f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_likely_index(tensor):\n",
    "    # find most likely label index for each element in the batch\n",
    "    return tensor.argmax(dim=-1)\n",
    "\n",
    "\n",
    "# Given an item form the test_dataset, returns an example for predict() function\n",
    "# numpytype: set it to True to return numpy nd-array\n",
    "def make_example(data_item):\n",
    "    label = data_item[0]\n",
    "    feat_seq = data_item[4]\n",
    "    return label, feat_seq\n",
    "\n",
    "\n",
    "# Return the prediction using nn.Module instance\n",
    "def predictNN(example, model=None):    # feat_seq: np.ndarray\n",
    "    model.eval()\n",
    "    batch = [example]   # make a batch with single example\n",
    "    tensor, target, lengths = collate_fn_lstm(batch)\n",
    "    # Use the model to predict the label index\n",
    "    output = model(tensor, lengths)\n",
    "    pred = get_likely_index(output)[0]   # indexing to get the prediction from batch    \n",
    "    return pred.item()\n",
    "\n",
    "\n",
    "# Run a prediction\n",
    "select_index = 1006\n",
    "item = DataItems[select_index]\n",
    "example = make_example(item)\n",
    "pred_index = predictNN(example, model=model_pt)\n",
    "pred_label  = Index_to_label[pred_index]\n",
    "phone, *_, feat_seq = item\n",
    "print(f\"Expected: {phone}. Predicted: {pred_label}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c39bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate the Given model on the whole dataset\n",
    "# ptmodel: set it to True for the PyTorch model\n",
    "def validateModel(model, predict_fn):\n",
    "    dataset = DataItems\n",
    "    expect_miss = 0      # keeps track of no. of mismatche between prediction in dataset vs model prediction\n",
    "    total_count = 0\n",
    "    correct_count = 0\n",
    "    for item in tqdm(dataset):\n",
    "        lbl, lbl_index, pred_index, seq_len, feat_seq = item\n",
    "        example = make_example(item)\n",
    "        pred = predict_fn(example, model=model)\n",
    "        if pred != pred_index: expect_miss += 1    # prediction does not match prediction in dataset\n",
    "        if pred == lbl_index: correct_count += 1   # prediction matched the actual label-index\n",
    "        total_count += 1\n",
    "    # Compute and print statistics\n",
    "    accuracy = (100.0 * correct_count) / total_count\n",
    "    print(f'Validation accuracy: {accuracy:.2f}%   correct_count: {correct_count}   expected-miss: {expect_miss}   total_count: {total_count}')\n",
    "    return accuracy, correct_count, expect_miss, total_count\n",
    "\n",
    "            \n",
    "# Validate the loaded model\n",
    "validateModel(model_pt, predictNN)\n",
    "print('Expected', Model_perf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4811183c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete names to avoid confusion\n",
    "del select_index, item, example, pred_index, pred_label, phone, feat_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acbd6c72",
   "metadata": {},
   "source": [
    "# Implementation Using torch.tensor Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be424ee8",
   "metadata": {},
   "source": [
    "## LSTM Refresher\n",
    "\n",
    "Following notes are taken from online book [d2l.ai](https://d2l.ai/chapter_recurrent-modern/lstm.html)\n",
    "\n",
    "![image.png](https://d2l.ai/_images/lstm-3.svg)\n",
    "\n",
    "\n",
    "Following operations are independent. As a result, they can be performed in parallel.\n",
    "\\begin{split}\\begin{aligned}\n",
    "\\mathbf{I}_t &= \\sigma(\\mathbf{X}_t \\mathbf{W}_{xi} + \\mathbf{H}_{t-1} \\mathbf{W}_{hi} + \\mathbf{b}_i),\\\\\n",
    "\\mathbf{F}_t &= \\sigma(\\mathbf{X}_t \\mathbf{W}_{xf} + \\mathbf{H}_{t-1} \\mathbf{W}_{hf} + \\mathbf{b}_f),\\\\\n",
    "\\mathbf{O}_t &= \\sigma(\\mathbf{X}_t \\mathbf{W}_{xo} + \\mathbf{H}_{t-1} \\mathbf{W}_{ho} + \\mathbf{b}_o), \\\\\n",
    "\\tilde{\\mathbf{C}}_t &= \\text{tanh}(\\mathbf{X}_t \\mathbf{W}_{xc} + \\mathbf{H}_{t-1} \\mathbf{W}_{hc} + \\mathbf{b}_c),\n",
    "\\end{aligned}\\end{split}\n",
    "\n",
    "Following operations depends on some of the above results and need to be performed in order (sequential).\n",
    "\\begin{split}\\begin{aligned}\n",
    "\\mathbf{C}_t &= \\mathbf{F}_t \\odot \\mathbf{C}_{t-1} + \\mathbf{I}_t \\odot \\tilde{\\mathbf{C}}_t.\\\\\n",
    "\\mathbf{H}_t &= \\mathbf{O}_t \\odot \\tanh(\\mathbf{C}_t).\n",
    "\\end{aligned}\\end{split}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19095935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, the weights of all gates (It, Ft, Ot, Ct) are merged into a single matrix\n",
    "for key, val in Model_state_dict.items():\n",
    "    print(key, val.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec2ae0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the LSTM cell\n",
    "# weight_ih: weights for input x\n",
    "# weight_hh: weights for hidden state h_prev\n",
    "def tensorLSTMCell(x, h_prev, c_prev, weight_ih, weight_hh, bias_ih, bias_hh, input_size, hidden_size):\n",
    "    gates = x @ weight_ih.t()  +  h_prev @ weight_hh.t()  +  bias_ih  +  bias_hh\n",
    "\n",
    "    i = torch.sigmoid(gates[:hidden_size])\n",
    "    f = torch.sigmoid(gates[hidden_size:2*hidden_size])\n",
    "    g = torch.tanh(gates[2*hidden_size:3*hidden_size])   # equivalent of ~Ct in above figure\n",
    "    o = torch.sigmoid(gates[3*hidden_size:])             # equivalent of Ot in above figure\n",
    "    #print(f.size())\n",
    "    #f * c_prev\n",
    "    c = f * c_prev + i * g   # Ct\n",
    "    h = o * torch.tanh(c)    # Ht\n",
    "    return h, c\n",
    "\n",
    "\n",
    "# Implements 3 layers of LSTM\n",
    "def tensorLSTM3(x, h_prev, c_prev, weight_dict, input_size, hidden_size):\n",
    "    # Perform compatability checks\n",
    "    layer_count=3\n",
    "    assert len(h_prev) == layer_count, \"You need to provide initial values for all layers\"\n",
    "    assert len(c_prev) == layer_count, \"You need to provide initial values for all layers\"\n",
    "    assert len(x) == input_size, \"Input size mismatch\"\n",
    "    # Layer-1\n",
    "    h0_cur, c0_cur = tensorLSTMCell(x, h_prev[0], c_prev[0], \n",
    "                                   weight_dict['lstm.weight_ih_l0'], weight_dict['lstm.weight_hh_l0'],\n",
    "                                   weight_dict['lstm.bias_ih_l0'], weight_dict['lstm.bias_hh_l0'],\n",
    "                                   input_size, hidden_size)\n",
    "    # Layer-2\n",
    "    h1_cur, c1_cur = tensorLSTMCell(h0_cur, h_prev[1], c_prev[1], \n",
    "                                   weight_dict['lstm.weight_ih_l1'], weight_dict['lstm.weight_hh_l1'],\n",
    "                                   weight_dict['lstm.bias_ih_l1'], weight_dict['lstm.bias_hh_l1'],\n",
    "                                   hidden_size, hidden_size)\n",
    "    # Layer-3\n",
    "    h2_cur, c2_cur = tensorLSTMCell(h1_cur, h_prev[2], c_prev[2], \n",
    "                                   weight_dict['lstm.weight_ih_l2'], weight_dict['lstm.weight_hh_l2'],\n",
    "                                   weight_dict['lstm.bias_ih_l2'], weight_dict['lstm.bias_hh_l2'],\n",
    "                                   hidden_size, hidden_size)\n",
    "    return (h0_cur, h1_cur, h2_cur), (c0_cur, c1_cur, c2_cur)\n",
    "    \n",
    "    \n",
    "\n",
    "# Implementation of ully connected layer \n",
    "def tensorFClayer(x, weight, bias):\n",
    "    return  x @ weight.t()  +  bias\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8123d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select and example to run through the manual model for validation\n",
    "label, feat_seq = make_example(DataItems[0])\n",
    "feat_seq = torch.from_numpy(feat_seq)\n",
    "feat_seq = feat_seq[:1, :]      # make it a sequence of 1 token\n",
    "seq_len  = torch.tensor(1)\n",
    "print('feat_seq:', feat_seq.size())\n",
    "\n",
    "# Initial states\n",
    "h0_3 = torch.zeros(3, Hparam['hidden_size'])\n",
    "c0_3 = torch.zeros(3, Hparam['hidden_size'])\n",
    "\n",
    "# Pass one token in sequence through the LSTM cell\n",
    "h_man3, c_man3 = tensorLSTM3(feat_seq[0], h0_3, c0_3, Model_state_dict, Hparam['input_size'], Hparam['hidden_size'])\n",
    "h_man = h_man3[2]\n",
    "print('h_man  :', h_man.size())\n",
    "\n",
    "\n",
    "# Pass the same sequence through the LSTM model layer\n",
    "model_pt.eval()\n",
    "out_model = model_pt(feat_seq.unsqueeze(0), seq_len.unsqueeze(0))\n",
    "h_model = model_pt.lstm_outpad[0]   # get the lstm layer output for the first token\n",
    "print('h_model:', h_model.size())\n",
    "\n",
    "\n",
    "# Compare the values in two methods\n",
    "abs_diff = torch.abs(h_man - h_model)\n",
    "max_diff = torch.max(abs_diff)\n",
    "tolerance = 10e-6\n",
    "print('max_diff:', max_diff.item())\n",
    "print('max_diff < Tolerance:', (max_diff<tolerance).item())\n",
    "assert max_diff<tolerance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e6bc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass the LSTM output through the Fully-Connected Layer\n",
    "out_man = tensorFClayer(h_man, Model_state_dict['fc.weight'], Model_state_dict['fc.bias'])\n",
    "print('out_man  :', out_man.size())\n",
    "\n",
    "# Compare the FC output with the LSTM model output\n",
    "print('out_model:', out_model.size())\n",
    "abs_diff = torch.abs(out_man - out_model)\n",
    "max_diff = torch.max(abs_diff)\n",
    "tolerance = 10e-6\n",
    "print('max_diff:', max_diff.item())\n",
    "print('max_diff < Tolerance:', (max_diff<tolerance).item())\n",
    "assert max_diff<tolerance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c0cf12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete names to avoid confusion\n",
    "del key, val\n",
    "del label, feat_seq, seq_len, h_man\n",
    "del h0_3, c0_3, h_man3, c_man3, out_model, h_model, abs_diff, max_diff, tolerance, out_man"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac1df0d",
   "metadata": {},
   "source": [
    "## Implement the Complete Manual Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7597b807",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensorModel(feat_seq):\n",
    "    # Initial states\n",
    "    h0_3 = torch.zeros(3, Hparam['hidden_size']).to(device) \n",
    "    c0_3 = torch.zeros(3, Hparam['hidden_size']).to(device)\n",
    "\n",
    "    # Pass sequence through the LSTM cell\n",
    "    h_prev, c_prev = h0_3, c0_3\n",
    "    for tok in feat_seq:\n",
    "        ht, ct = tensorLSTM3(tok, h_prev, c_prev, Model_state_dict, Hparam['input_size'], Hparam['hidden_size'])\n",
    "        h_prev, c_prev = ht, ct\n",
    "    last_hidden = ht[2]\n",
    "    out = tensorFClayer(last_hidden, Model_state_dict['fc.weight'], Model_state_dict['fc.bias'])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbed7c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select and example to run through the manual model for validation\n",
    "label, feat_seq = make_example(DataItems[0])\n",
    "feat_seq = torch.from_numpy(feat_seq)\n",
    "seq_len = torch.tensor(len(feat_seq))\n",
    "print('feat_seq:', feat_seq.size())\n",
    "\n",
    "out_man = tensorModel(feat_seq)\n",
    "print('out_man:', out_man.size())\n",
    "\n",
    "out_model = model_pt(feat_seq.unsqueeze(0), seq_len.unsqueeze(0))\n",
    "print('out_model:', out_model.size())\n",
    "\n",
    "# Compare the two outputs\n",
    "abs_diff = torch.abs(out_man - out_model)\n",
    "max_diff = torch.max(abs_diff)\n",
    "tolerance = 10e-6\n",
    "print('max_diff:', max_diff.item())\n",
    "print('max_diff < Tolerance:', (max_diff<tolerance).item())\n",
    "assert max_diff<tolerance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b381860a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Driver for manual tensor based model\n",
    "def predict_tensorModel(example, **kwargs):\n",
    "    # Use the model to predict the label of the waveform\n",
    "    label, feat_seq = example\n",
    "    feat_seq = torch.from_numpy(feat_seq)\n",
    "    output = tensorModel(feat_seq)\n",
    "    pred = get_likely_index(output)   # indexing to get the prediction from batch\n",
    "    return pred.item()\n",
    "\n",
    "\n",
    "# test above function\n",
    "item = DataItems[120]\n",
    "print_dataItem(item)\n",
    "example = make_example(item)\n",
    "pred = predict_tensorModel(example)\n",
    "print('pred:', pred)\n",
    "\n",
    "# Run on entire test-dataset\n",
    "accuracy, correct_count, expect_miss, total_count = validateModel(None, predict_tensorModel)\n",
    "print('Expected', Model_perf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87458533",
   "metadata": {},
   "outputs": [],
   "source": [
    "del abs_diff, accuracy, correct_count, example\n",
    "del expect_miss, feat_seq, item, label\n",
    "del max_diff, out_man, out_model, pred, seq_len\n",
    "del tolerance, total_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b1a3d5",
   "metadata": {},
   "source": [
    "# Implement Using Numpy Matrix Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6d797d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy weights as numpy ndarray\n",
    "Weights_np = {}\n",
    "for k, v in Model_state_dict.items():\n",
    "    Weights_np[k] = Model_state_dict[k].detach().numpy()\n",
    "    \n",
    "for k, v in Weights_np.items():\n",
    "    print(k, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b39039",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transpose the weights beforehand\n",
    "for k, v in Weights_np.items():\n",
    "    if 'weight' in k:\n",
    "        Weights_np[k] = v.T\n",
    "        print('Transposed:', k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5a8d30",
   "metadata": {},
   "source": [
    "## Layer and Model Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3ff269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sigmoid activation in numpy\n",
    "def npSigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "# Defining the LSTM cell\n",
    "# weight_ih: weights for input x\n",
    "# weight_hh: weights for hidden state h_prev\n",
    "def npLSTMCell(x, h_prev, c_prev, weight_ih, weight_hh, bias_ih, bias_hh, input_size, hidden_size):\n",
    "    gates = x @ weight_ih + h_prev @ weight_hh + bias_ih + bias_hh\n",
    "\n",
    "    i = npSigmoid(gates[:hidden_size])\n",
    "    f = npSigmoid(gates[hidden_size:2*hidden_size])\n",
    "    g = np.tanh(gates[2*hidden_size:3*hidden_size])   # equivalent of ~Ct in above figure\n",
    "    o = npSigmoid(gates[3*hidden_size:])             # equivalent of Ot in above figure\n",
    "    c = f * c_prev + i * g   # Ct\n",
    "    h = o * np.tanh(c)    # Ht\n",
    "    return h, c\n",
    "\n",
    "\n",
    "# Implements 3 layers of LSTM\n",
    "def npLSTM3(x, h_prev, c_prev, weight_dict, input_size, hidden_size):\n",
    "    # Perform compatability checks\n",
    "    layer_count=3\n",
    "    assert len(h_prev) == layer_count, \"You need to provide initial values for all layers\"\n",
    "    assert len(c_prev) == layer_count, \"You need to provide initial values for all layers\"\n",
    "    assert len(x) == input_size, \"Input size mismatch\"\n",
    "    # Layer-1\n",
    "    h0_cur, c0_cur = npLSTMCell(x, h_prev[0], c_prev[0], \n",
    "                                weight_dict['lstm.weight_ih_l0'], weight_dict['lstm.weight_hh_l0'],\n",
    "                                weight_dict['lstm.bias_ih_l0'], weight_dict['lstm.bias_hh_l0'],\n",
    "                                input_size, hidden_size)\n",
    "    # Layer-2\n",
    "    h1_cur, c1_cur = npLSTMCell(h0_cur, h_prev[1], c_prev[1], \n",
    "                                weight_dict['lstm.weight_ih_l1'], weight_dict['lstm.weight_hh_l1'],\n",
    "                                weight_dict['lstm.bias_ih_l1'], weight_dict['lstm.bias_hh_l1'],\n",
    "                                hidden_size, hidden_size)\n",
    "    # Layer-3\n",
    "    h2_cur, c2_cur = npLSTMCell(h1_cur, h_prev[2], c_prev[2], \n",
    "                                weight_dict['lstm.weight_ih_l2'], weight_dict['lstm.weight_hh_l2'],\n",
    "                                weight_dict['lstm.bias_ih_l2'], weight_dict['lstm.bias_hh_l2'],\n",
    "                                hidden_size, hidden_size)\n",
    "    return (h0_cur, h1_cur, h2_cur), (c0_cur, c1_cur, c2_cur)\n",
    "    \n",
    "    \n",
    "\n",
    "# Implementation of ully connected layer \n",
    "def npFClayer(x, weight, bias):\n",
    "    return x @ weight + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c9c3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete Model using numpy\n",
    "def npModel(feat_seq):\n",
    "    # Initial states\n",
    "    h0_3 = np.zeros((3, Hparam['hidden_size']))\n",
    "    c0_3 = np.zeros((3, Hparam['hidden_size']))\n",
    "\n",
    "    # Pass sequence through the LSTM cell\n",
    "    h_prev, c_prev = h0_3, c0_3\n",
    "    for tok in feat_seq:\n",
    "        ht, ct = npLSTM3(tok, h_prev, c_prev, Weights_np, Hparam['input_size'], Hparam['hidden_size'])\n",
    "        h_prev, c_prev = ht, ct\n",
    "    last_hidden = ht[2]\n",
    "    out = npFClayer(last_hidden, Weights_np['fc.weight'], Weights_np['fc.bias'])\n",
    "    return out\n",
    "\n",
    "\n",
    "# Select and example to run through the numpy model for validation\n",
    "label, feat_seq = make_example(DataItems[0])\n",
    "feat_seq = torch.from_numpy(feat_seq)\n",
    "seq_len = torch.tensor(len(feat_seq))\n",
    "feat_seq = feat_seq.to(device)\n",
    "print('feat_seq:', feat_seq.size())\n",
    "out_model = model_pt(feat_seq.unsqueeze(0), seq_len.unsqueeze(0))\n",
    "print('out_model:', out_model.size())\n",
    "\n",
    "feat_seq = feat_seq.to('cpu').detach().numpy()\n",
    "out_np = npModel(feat_seq)\n",
    "print('out_np:', out_np.shape)\n",
    "\n",
    "# Compare the two outputs\n",
    "out_model = out_model.to('cpu').detach().numpy()\n",
    "abs_diff = np.abs(out_np - out_model)\n",
    "max_diff = np.max(abs_diff)\n",
    "tolerance = 10e-6\n",
    "print('max_diff:', max_diff.item())\n",
    "print('max_diff < Tolerance:', (max_diff<tolerance).item())\n",
    "assert max_diff<tolerance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b97c943",
   "metadata": {},
   "source": [
    "## Validate Model on Entire Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7e2feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given a numpy array, returns the index of the maximum value\n",
    "def get_likely_index_np(nparray):\n",
    "    return nparray.argmax()\n",
    "\n",
    "\n",
    "# Driver for manual numpy based model\n",
    "def predict_npModel(example, **kwargs):\n",
    "    # Use the model to predict the label of the waveform\n",
    "    label, feat_seq = example\n",
    "    output = npModel(feat_seq)\n",
    "    pred = get_likely_index_np(output)   # indexing to get the prediction from batch\n",
    "    return pred.item()\n",
    "\n",
    "\n",
    "# item: (label, label_index, sequence_length, feature_length, predicted_index, feature_seqeunce)\n",
    "item = DataItems[120]\n",
    "print_dataItem(item)\n",
    "example = make_example(item)\n",
    "pred = predict_npModel(example)\n",
    "print('pred:', pred)\n",
    "\n",
    "# Run on entire test-dataset\n",
    "accuracy, correct_count, expect_miss, total_count = validateModel(None, predict_npModel)\n",
    "print('Expected', Model_perf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "79bc6dfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 1.7G\r\n",
      "-rw-rw-r-- 1 makabir makabir  310 Jun 24 16:57 README.md\r\n",
      "-rw-rw-r-- 1 makabir makabir 1.3M Jun 26 12:52 curated-dataset.pt\r\n",
      "-rw-rw-r-- 1 makabir makabir 5.4M Jun 27 18:24 trained-lstm250-83.09p.pt\r\n",
      "-rw-rw-r-- 1 makabir makabir  829 Jun 27 18:30 label-to-index.pt\r\n",
      "-rw-rw-r-- 1 makabir makabir 167M Jun 28 23:12 test-features.pt\r\n",
      "-rw-rw-r-- 1 makabir makabir 1.2G Jun 28 23:15 train-features.pt\r\n",
      "-rw-rw-r-- 1 makabir makabir 125M Jun 28 23:48 Test_feat.pt\r\n",
      "-rw-rw-r-- 1 makabir makabir 5.4M Jun 28 23:48 trained-lstm250-82.26p.pt\r\n",
      "-rw-rw-r-- 1 makabir makabir 125M Jun 28 23:49 Test_feat-82.26p.pt\r\n",
      "drwxrwxr-x 2 makabir makabir 4.0K Jun 29 13:23 backup\r\n",
      "-rw-rw-r-- 1 makabir makabir 5.4M Jun 29 15:14 trained-lstm250.pt\r\n",
      "-rw-rw-r-- 1 makabir makabir 125M Jun 29 15:28 test-export-ds.pt\r\n",
      "-rw-rw-r-- 1 makabir makabir 7.9M Jun 29 18:06 model-params-np.pt\r\n"
     ]
    }
   ],
   "source": [
    "save_path = './session/model-params-np.pt'\n",
    "export_params = {\n",
    "    'accuracy' : accuracy,\n",
    "    'correct_count' : correct_count,\n",
    "    'Hparam' : Hparam,\n",
    "    'index_to_label': Index_to_label,\n",
    "    'weights_dict' : Weights_np\n",
    "}\n",
    "torch.save(export_params, save_path)\n",
    "!ls -ltrh ./session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f403d37",
   "metadata": {},
   "source": [
    "# Update the dataset with the Numpy Model Predicted index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc87075",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d2c250f5",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ee4583",
   "metadata": {},
   "source": [
    "# Export Numpy Model as sqlite3 DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10fe243",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eef4054d",
   "metadata": {},
   "source": [
    "# Export the Dataset as sqlite3 DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2ce1b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
