{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd08cf31",
   "metadata": {},
   "source": [
    "# LSTM-250 Numpy Model Extraction\n",
    "\n",
    "## Goals\n",
    "\n",
    "- Loads Dataset and Model from training notebook and validates.\n",
    "- Translates the model into Numpy operations and validates.\n",
    "- Dataset updated with the accuracy from the Numpy model.\n",
    "- Model and dataset exported as sqlite3 database for implementation in C.\n",
    "\n",
    "**NOTE:** The dataset exported by the training notebook may have incorrect predicted index due to several iterations of model training and not updating the dataset. We'll re-run the predictions here and update the predicted index in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175c8eff",
   "metadata": {},
   "source": [
    "# Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7998845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch version: 2.0.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import IPython.display as ipd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "#if torch.cuda.is_available():\n",
    "#    device = torch.device('cuda')\n",
    "#else:\n",
    "#    device = torch.device('cpu')\n",
    "\n",
    "#print('Using PyTorch version:', torch.__version__, ' Device:', device)\n",
    "print('Using PyTorch version:', torch.__version__)\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17026675",
   "metadata": {},
   "source": [
    "# Load and Validate torch.nn.Module Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13052a08",
   "metadata": {},
   "source": [
    "## Define Model\n",
    "\n",
    "**NOTE:** Always copy the following cell from the training notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "595a1648",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.utils.rnn as rnn_utils\n",
    "\n",
    "\n",
    "# LSTM model definition\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.num_classes = num_classes\n",
    "        self.debug = False    # Set it to true to print debug info\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=0.2)\n",
    "        #self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "    \n",
    "    # Expects a padded_sequence of batched input and the lengths of the sequences\n",
    "    def forward(self, pad_seq, lengths):        \n",
    "        if self.debug: print('DEBUG START: LSTM model ---')\n",
    "\n",
    "        # Extract batch size for initialization of hidden state\n",
    "        batch_size = len(pad_seq)\n",
    "            \n",
    "        # Set initial hidden and cell states\n",
    "        h0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device) \n",
    "        c0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device)\n",
    "        \n",
    "        # Convert padded sequence to variable length packed sequence for LSTM\n",
    "        packed_seq = rnn_utils.pack_padded_sequence(pad_seq, lengths, enforce_sorted=False, batch_first=True)\n",
    "        \n",
    "        # Forward propagate LSTM, returns a packed sequence\n",
    "        out_packed, _ = self.lstm(packed_seq, (h0, c0))\n",
    "        \n",
    "        # Extract final hidden states of each sequence for the output layer\n",
    "        out_pad, out_lens = rnn_utils.pad_packed_sequence(out_packed, batch_first=True)\n",
    "        out_indx = out_lens - 1   # indices of the last valid hidden state in the padded sequence\n",
    "        last_hidden = out_pad[range(batch_size), out_indx].contiguous()  # select the last valid state in each sequence, and make them contiguous for efficiency\n",
    "                \n",
    "        if self.debug:\n",
    "            print('last_hidden size:', last_hidden.size())\n",
    "            print('last_hidden:\\n', last_hidden)\n",
    "        \n",
    "        # Decode the hidden state of the last time step only (for whole batch)\n",
    "        out = self.fc(last_hidden)\n",
    "        if self.debug: print('DEBUG END: LSTM model ---')\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548e7733",
   "metadata": {},
   "source": [
    "## Load Saved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f52cfd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 1.7G\n",
      "-rw-rw-r-- 1 makabir makabir  310 Jun 24 16:57 README.md\n",
      "-rw-rw-r-- 1 makabir makabir 1.3M Jun 26 12:52 curated-dataset.pt\n",
      "-rw-rw-r-- 1 makabir makabir 5.4M Jun 27 18:24 trained-lstm250-83.09p.pt\n",
      "-rw-rw-r-- 1 makabir makabir  829 Jun 27 18:30 label-to-index.pt\n",
      "-rw-rw-r-- 1 makabir makabir 167M Jun 28 23:12 test-features.pt\n",
      "-rw-rw-r-- 1 makabir makabir 1.2G Jun 28 23:15 train-features.pt\n",
      "-rw-rw-r-- 1 makabir makabir 125M Jun 28 23:48 Test_feat.pt\n",
      "-rw-rw-r-- 1 makabir makabir 5.4M Jun 28 23:48 trained-lstm250-82.26p.pt\n",
      "-rw-rw-r-- 1 makabir makabir 125M Jun 28 23:49 Test_feat-82.26p.pt\n",
      "drwxrwxr-x 2 makabir makabir 4.0K Jun 29 13:23 backup\n",
      "-rw-rw-r-- 1 makabir makabir 5.4M Jun 29 15:14 trained-lstm250.pt\n",
      "-rw-rw-r-- 1 makabir makabir 125M Jun 29 15:28 test-export-ds.pt\n",
      "\n",
      "dict_keys(['accuracy', 'correct_count', 'index_to_label', 'Hparam', 'state_dict'])\n",
      "Hparam: {'input_size': 123, 'hidden_size': 250, 'num_layers': 3, 'num_classes': 39}\n",
      "Model_perf: Model Performance:   accuracy: 73.03%   correct_count: 5355\n",
      "LSTM(\n",
      "  (lstm): LSTM(123, 250, num_layers=3, batch_first=True, dropout=0.2)\n",
      "  (fc): Linear(in_features=250, out_features=39, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "!ls -ltrh ./session/\n",
    "print('')\n",
    "\n",
    "# Load saved model dictionary\n",
    "model_path = './session/trained-lstm250.pt'\n",
    "model_dict = torch.load(model_path)\n",
    "print(model_dict.keys())\n",
    "\n",
    "\n",
    "# Parse the values for easier use\n",
    "Accuracy = model_dict['accuracy']\n",
    "Correct_count = model_dict['correct_count']\n",
    "Index_to_label = model_dict['index_to_label']\n",
    "Label_to_index = {label:index for index, label in Index_to_label.items()}\n",
    "Hparam = model_dict['Hparam']\n",
    "Model_state_dict = model_dict['state_dict']\n",
    "Model_perf = f'Model Performance:   accuracy: {Accuracy:.2f}%   correct_count: {Correct_count}'  # to be used later\n",
    "print('Hparam:', Hparam)\n",
    "print('Model_perf:', Model_perf)\n",
    "\n",
    "\n",
    "# move all weights to cpu\n",
    "#for key in Model_state_dict: \n",
    "#    Model_state_dict[key] = Model_state_dict[key].to('cpu')\n",
    "    \n",
    "    \n",
    "# Instantiate the model\n",
    "model_pt = LSTM(Hparam['input_size'], Hparam['hidden_size'], Hparam['num_layers'], Hparam['num_classes'])\n",
    "model_pt.load_state_dict(Model_state_dict)\n",
    "model_pt.to('cpu')\n",
    "model_pt.eval()     # we are always evaluating here\n",
    "print(model_pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "337a46d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete names to avoid confusions later\n",
    "del model_path, model_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b036b990",
   "metadata": {},
   "source": [
    "## Load Saved Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d609141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['label_dict', 'dataset_schema', 'dataset'])\n",
      "DS_loaded len: 7333\n",
      "schema: (label, label_index, predicted_index, sequence_length, feature_sequence)\n",
      "INFO: Dataset and Model label-to-index matched\n",
      "label: h#, label_index: 6, predicted_index: 6, sequence_length: 38, \n",
      "feature_sequence shape: (38, 123), feature_seq type: <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# Prints information about dataset item\n",
    "def print_dataItem(item):\n",
    "    mstr = f\"label: {item[0]}, label_index: {item[1]}, predicted_index: {item[2]}, sequence_length: {item[3]},\"\n",
    "    mstr2 = f\"\\nfeature_sequence shape: {item[4].shape}, feature_seq type: {type(item[4])}\"\n",
    "    print(mstr, mstr2)\n",
    "\n",
    "    \n",
    "# Load the test dataset\n",
    "ds_path = \"./session/test-export-ds.pt\"\n",
    "DS_loaded = torch.load(ds_path)\n",
    "print(DS_loaded.keys())\n",
    "print('DS_loaded len:', len(DS_loaded['dataset']))\n",
    "print('schema:', DS_loaded['dataset_schema'])\n",
    "\n",
    "\n",
    "# Make sure the label-to-index dictionary matches the one in the model\n",
    "for key in DS_loaded['label_dict']:\n",
    "    assert DS_loaded['label_dict'][key] == Label_to_index[key], 'Dataset and Model Label-to-index are different'\n",
    "print('INFO: Dataset and Model label-to-index matched')\n",
    "\n",
    "\n",
    "# show an item information\n",
    "item = DS_loaded['dataset'][0]\n",
    "print_dataItem(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1bcf99db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete names to avoid confusions later\n",
    "del ds_path, key, item"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1bc405",
   "metadata": {},
   "source": [
    "## Validate Loaded Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4802b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padding is needed to make the batch <tensor> from <list> of variable length sequences\n",
    "# The padding values are not passed to the LSTM during trainig/testing\n",
    "def pad_sequence_lstm(batch):\n",
    "    # Make all tensor in a batch the same length by padding with zeros\n",
    "    batch = rnn_utils.pad_sequence(batch, batch_first=True, padding_value=0.)\n",
    "    return batch\n",
    "\n",
    "\n",
    "# Gets the list of audio and labels as batch then\n",
    "# converts them into sequence of features for the model.\n",
    "# Adds padding to build the batch tensor\n",
    "def collate_fn_lstm(batch):\n",
    "    tensors, targets, lengths = [], [], []   # lengths is needed for pack_padded_sequence  in LSTM.forward()\n",
    "\n",
    "    # Gather in lists, and encode labels as indices\n",
    "    for item in batch:\n",
    "        label, feat_seq = item\n",
    "        feat_seq_tensor = torch.from_numpy(feat_seq)\n",
    "        tensors += [feat_seq_tensor]\n",
    "        targets += [Label_to_index[label]]\n",
    "        lengths.append(feat_seq_tensor.size()[0])\n",
    "\n",
    "    # Group the list of tensors into a batched tensor\n",
    "    tensors = pad_sequence_lstm(tensors)\n",
    "    targets = torch.tensor(targets)\n",
    "    lengths = torch.tensor(lengths)\n",
    "    return tensors, targets, lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "837c37c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected: iy. Predicted: iy.\n"
     ]
    }
   ],
   "source": [
    "def get_likely_index(tensor):\n",
    "    # find most likely label index for each element in the batch\n",
    "    return tensor.argmax(dim=-1)\n",
    "\n",
    "\n",
    "# Given an item form the test_dataset, returns an example for predict() function\n",
    "# numpytype: set it to True to return numpy nd-array\n",
    "def make_example(data_item):\n",
    "    label = item[0]\n",
    "    feat_seq = data_item[4]\n",
    "    return label, feat_seq\n",
    "\n",
    "\n",
    "# Return the prediction using nn.Module instance\n",
    "def predictNN(example, model=None):    # feat_seq: np.ndarray\n",
    "    model.eval()\n",
    "    batch = [example]   # make a batch with single example\n",
    "    tensor, target, lengths = collate_fn_lstm(batch)\n",
    "    # Use the model to predict the label index\n",
    "    output = model(tensor, lengths)\n",
    "    pred = get_likely_index(output)[0]   # indexing to get the prediction from batch    \n",
    "    return pred.item()\n",
    "\n",
    "\n",
    "# Run a prediction\n",
    "select_index = 1006\n",
    "item = DS_loaded['dataset'][select_index]\n",
    "example = make_example(item)\n",
    "pred_index = predictNN(example, model=model_pt)\n",
    "pred_label  = Index_to_label[pred_index]\n",
    "phone, *_, feat_seq = item\n",
    "print(f\"Expected: {phone}. Predicted: {pred_label}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2edf1c06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e7a9cef88d04a01acf13c95912308c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7333 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 73.03%   correct_count: 5355   expected-miss: 0   total_count: 7333\n",
      "Expected Model Performance:   accuracy: 73.03%   correct_count: 5355\n"
     ]
    }
   ],
   "source": [
    "# Validate the Given model on the whole dataset\n",
    "# ptmodel: set it to True for the PyTorch model\n",
    "def validateModel(model, predict_fn):\n",
    "    dataset = DS_loaded['dataset']\n",
    "    expect_miss = 0      # keeps track of no. of mismatche between prediction in dataset vs model prediction\n",
    "    total_count = 0\n",
    "    correct_count = 0\n",
    "    for item in tqdm(dataset):\n",
    "        lbl, lbl_index, pred_index, seq_len, feat_seq = item\n",
    "        example = make_example(item)\n",
    "        pred = predict_fn(example, model=model)\n",
    "        if pred != pred_index: expect_miss += 1    # prediction does not match prediction in dataset\n",
    "        if pred == lbl_index: correct_count += 1   # prediction matched the actual label-index\n",
    "        total_count += 1\n",
    "    # Compute and print statistics\n",
    "    accuracy = (100.0 * correct_count) / total_count\n",
    "    print(f'Validation accuracy: {accuracy:.2f}%   correct_count: {correct_count}   expected-miss: {expect_miss}   total_count: {total_count}')\n",
    "    return accuracy, correct_count, expect_miss, total_count\n",
    "\n",
    "            \n",
    "# Validate the loaded model\n",
    "validateModel(model_pt, predictNN)\n",
    "print('Expected', Model_perf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3e4a16",
   "metadata": {},
   "source": [
    "# Implementation Using torch.tensor Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408bc58b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "70a7d043",
   "metadata": {},
   "source": [
    "# Implement Using Numpy Matrix Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9427b998",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "80a8d51e",
   "metadata": {},
   "source": [
    "# Update the dataset with the Numpy Model Predicted index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8a6dfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d5cea6af",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86ccd94",
   "metadata": {},
   "source": [
    "# Export Numpy Model as sqlite3 DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bb5f2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "853d8adb",
   "metadata": {},
   "source": [
    "# Export the Dataset as sqlite3 DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f979f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
