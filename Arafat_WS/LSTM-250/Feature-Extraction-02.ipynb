{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10b9d6ee",
   "metadata": {},
   "source": [
    "# Feature Extraction for Phoneme Recognition on TIMIT\n",
    "\n",
    "## Goals\n",
    "\n",
    "- Loading and testing the datasets exported by the previous notebook.\n",
    "- Feature design for the LSTM-250 network.\n",
    "- Feature extraction from the TIMIT dataset.\n",
    "- Exporting the features as standalone dataset for training the network.\n",
    "    - Feature dataset record: (phoneme, feature-sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ed2982",
   "metadata": {},
   "source": [
    "# Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68ee34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print('Using PyTorch version:', torch.__version__, ' Device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74cb192",
   "metadata": {},
   "source": [
    "# Loading and Testing the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5b2c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_path = './session/curated-dataset.pt'\n",
    "ds_dict = torch.load(ds_path)\n",
    "print(ds_dict.keys())\n",
    "print(ds_dict['note'])\n",
    "\n",
    "Train_ds = ds_dict['train']\n",
    "Test_ds  = ds_dict['test']\n",
    "\n",
    "print('Train_ds:', len(Train_ds))\n",
    "ipd.display(Train_ds[:3])\n",
    "print('Test_ds:', len(Test_ds))\n",
    "ipd.display(Test_ds[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a42b647",
   "metadata": {},
   "outputs": [],
   "source": [
    "rec = Train_ds[1]\n",
    "phone, audio_path, start, end = rec\n",
    "wave, rate = librosa.load(audio_path, sr=None)\n",
    "phone_wave = wave[start:end]\n",
    "print(phone)\n",
    "ipd.display(ipd.Audio(phone_wave, rate=rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f236a17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete redundant variables to avoid confusion\n",
    "del ds_path, ds_dict\n",
    "del rec, phone, audio_path, start, end, wave, rate, phone_wave\n",
    "print(dir())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a52f60",
   "metadata": {},
   "source": [
    "## Convert to Audio dataset\n",
    "\n",
    "Convert records from (phoneme, path-to-audio, start-index, end-index) to (phoneme, wave, rate)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e2faba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given a file path, returns the audio waveform and the sampling rate.\n",
    "# Mainly used for caching already loaded files.\n",
    "audio_cache = {}    # Caching loaded audio files for faster processing\n",
    "def getAudio(audio_path):\n",
    "    if audio_path not in audio_cache:\n",
    "        wave, rate = librosa.load(audio_path, sr=None)    \n",
    "        audio_cache[audio_path] = (wave, rate)\n",
    "    return audio_cache[audio_path]\n",
    "\n",
    "\n",
    "# Given file path, start, and end indices, returns the audio slice and the sampling rate\n",
    "def getAudioSlice(audio_path, start, end):\n",
    "    wave, rate = getAudio(audio_path)\n",
    "    return wave[start:end], rate\n",
    "\n",
    "\n",
    "# Without caching: 14 seconds\n",
    "# With caching: < 1sec\n",
    "# Test above function\n",
    "for rec in tqdm(Train_ds):    \n",
    "    _, audio_path, *_ = rec\n",
    "    getAudio(audio_path)\n",
    "    \n",
    "    \n",
    "# delete redundant variables to avoid confusion\n",
    "del rec, audio_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5a32d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given a phoneme record list, returns an audio record list: (phoneme, wave, rate)\n",
    "def makeAudioDS(list_phone_rec):\n",
    "    audio_ds = []\n",
    "    for phone_rec in list_phone_rec:\n",
    "        phone, audio_path, start, end = phone_rec\n",
    "        wave, rate = getAudioSlice(audio_path, start, end)\n",
    "        audio_rec = [phone, wave, rate]\n",
    "        audio_ds.append(audio_rec)\n",
    "    return audio_ds\n",
    "\n",
    "\n",
    "# Convert to audio datasets\n",
    "Train_audio_ds = makeAudioDS(Train_ds)\n",
    "Test_audio_ds  = makeAudioDS(Test_ds)\n",
    "        \n",
    "print('Train_audio_ds:', len(Train_audio_ds))\n",
    "print('Test_audio_ds :', len(Test_audio_ds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a90d389",
   "metadata": {},
   "source": [
    "# Feature Design\n",
    "\n",
    "**NOTE:**\n",
    "- Feature vector is designed following [[Speech-Recog paper]](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6638947)\n",
    "- Mel-spectrogram is used as the base feature, 40 of Mel bands are generated.\n",
    "- The energy term is computed using the mel-spectrogram.\n",
    "- First and second order derivatives of those terms are used.\n",
    "- Total length of the feature vector: 41 x 3 = 123."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e4944c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given an audio waveform, get the MFCC coefficients\n",
    "# Params,\n",
    "#   n_mfcc    : no. of MFCC coefficient to return\n",
    "#   n_mels    : number of Mel bands to generate\n",
    "#   fft_window: length of the FFT window\n",
    "#   hop_len   : number of audio samples between adjacent STFT columns.\n",
    "# Note: Change fft_window and hop_len to play with the sequence lengths.\n",
    "#def getMFCC(wave, sample_rate, n_mfcc, fft_window, hop_length, n_mels):\n",
    "#    #mfcc = librosa.feature.mfcc(y=wave, sr=sample_rate, n_mfcc=n_mfcc, n_fft=fft_window, hop_length=hop_length, n_mels=n_mels)\n",
    "#    mel_spec = librosa.feature.melspectrogram(y=wave, sr=sample_rate, n_fft=fft_window, hop_length=hop_length, n_mels=n_mels)\n",
    "#    log_mel_spec = librosa.power_to_db(mel_spec)  # Convert to log-scale\n",
    "#    return log_mel_spec\n",
    "    #return mfcc\n",
    "\n",
    "\n",
    "# Given a sequence of mfcc coefficients, returns a sequence of corresponding energy terms\n",
    "#def getEnergy(mfcc_seq):\n",
    "#    energy_seq = np.sum(mfcc_seq**2, axis=0)\n",
    "#    return energy_seq\n",
    "\n",
    "\n",
    "# Given an audio waveform, get the mel-spectrogram\n",
    "# Params,\n",
    "#   n_mels     : number of Mel bands to generate\n",
    "#   fft_window : length of the FFT window\n",
    "#   hop_length : number of audio samples between adjacent STFT columns.\n",
    "# Note: Change fft_window and hop_len to play with the sequence lengths.\n",
    "def getMelSpec(wave, sample_rate, n_mels, fft_window, hop_length):\n",
    "    mel_spec = librosa.feature.melspectrogram(y=wave, sr=sample_rate, n_fft=fft_window, hop_length=hop_length, n_mels=n_mels)\n",
    "    log_mel_spec = librosa.power_to_db(mel_spec)  # Convert to log-scale\n",
    "    return log_mel_spec\n",
    "\n",
    "\n",
    "# Given a waveform, compute energy (in decibel) in each frame\n",
    "def getEnergy(wave, frame_length, hop_length):\n",
    "    energy = librosa.feature.rms(y=wave, frame_length=frame_length, hop_length=hop_length)\n",
    "    log_energy = librosa.power_to_db(energy)\n",
    "    return log_energy\n",
    "\n",
    "\n",
    "# Given a sequence, computes the derivative of order=order.\n",
    "def getDelta(seq, order):\n",
    "    delta = librosa.feature.delta(seq, order=order)\n",
    "    return delta\n",
    "\n",
    "\n",
    "# Plotting utilities ---\n",
    "def plotAudio(wave, sample_rate, axis):\n",
    "    duration = len(wave) / sample_rate\n",
    "    time = np.linspace(0, duration, len(wave))\n",
    "    axis.plot(time, wave)\n",
    "    \n",
    "\n",
    "# Use librosa.display.specshow to display 2D features\n",
    "def plotSpecshow(data, fig, axis):\n",
    "    img = librosa.display.specshow(data, ax=axis)\n",
    "    fig.colorbar(img, ax=axis)\n",
    "    return img\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833ea4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test above functions ---\n",
    "# Get an audio\n",
    "rec = Test_audio_ds[1200]\n",
    "phone, wave, rate = rec\n",
    "print('phone:', phone, '  wave:', len(wave), '  rate:', rate)\n",
    "\n",
    "#mfcc = getMFCC(wave, rate, n_mfcc=40, fft_window=64, hop_length=16, n_mels=40)\n",
    "#print('mfcc:', mfcc.shape)\n",
    "\n",
    "mel_spec = getMelSpec(wave, rate, n_mels=40, fft_window=64, hop_length=16)\n",
    "print('mel_spec:', mel_spec.shape)\n",
    "\n",
    "#energy = getEnergy(mfcc)\n",
    "energy = getEnergy(wave, frame_length=64, hop_length=16)\n",
    "print('energy:', energy.shape)\n",
    "\n",
    "#mfcc_eng = np.vstack([mfcc, energy])\n",
    "#print('mfcc_eng:', mfcc_eng.shape)\n",
    "\n",
    "mel_eng = np.vstack([mel_spec, energy])\n",
    "\n",
    "delta1 = getDelta(mel_eng, order=1)\n",
    "delta2 = getDelta(mel_eng, order=2)\n",
    "print('delta1:', delta1.shape)\n",
    "print('delta2:', delta2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846023f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the features\n",
    "print('phoneme:', phone)\n",
    "ipd.display(ipd.Audio(wave, rate=rate))\n",
    "\n",
    "fig = plt.figure(figsize=(3*4, 7))\n",
    "fig.subplots_adjust(hspace=0.5)\n",
    "fig.tight_layout()\n",
    "\n",
    "ax_wave = fig.add_subplot(3, 1, 1)\n",
    "plotAudio(wave, rate, ax_wave)\n",
    "ax_wave.set_title('Audio')\n",
    "\n",
    "ax_mel = fig.add_subplot(3, 2, 3)\n",
    "ax_mel.set_title('Mel Spectrogram')\n",
    "plotSpecshow(mel_spec, fig, ax_mel)\n",
    "\n",
    "ax_energy = fig.add_subplot(3, 2, 4)\n",
    "ax_energy.set_title('Energy')\n",
    "ax_energy.plot(energy[0], color='r')\n",
    "\n",
    "ax_delta1 = fig.add_subplot(3, 2, 5)\n",
    "ax_delta1.set_title('Delta-1')\n",
    "plotSpecshow(delta1, fig, ax_delta1)\n",
    "\n",
    "ax_delta2 = fig.add_subplot(3, 2, 6)\n",
    "ax_delta2.set_title('Delta-2')\n",
    "plotSpecshow(delta2, fig, ax_delta2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958b07df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete redundant variables to avoid confusion\n",
    "del rec, phone, wave, rate\n",
    "del mel_spec, energy, mel_eng, delta1, delta2\n",
    "del ax_wave, ax_mel, ax_energy, ax_delta1, ax_delta2, fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f93bb85",
   "metadata": {},
   "source": [
    "## Check Audio Dataset Distribution\n",
    "\n",
    "Check the audio dataset to determine the parameters for the features.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4bd4454",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import inf as INF\n",
    "\n",
    "\n",
    "# Given a audio dataset, returns the record with min and max audio lengths\n",
    "def getMinMaxRec(ds_list):\n",
    "    min_len = INF\n",
    "    max_len = -INF\n",
    "    min_rec = None\n",
    "    max_rec = None\n",
    "    all_len = []\n",
    "    for audio_rec in ds_list:    # rec: (phoneme, wave, rate)\n",
    "        phone_len = len(audio_rec[1])\n",
    "        if phone_len < min_len:\n",
    "            min_len = phone_len\n",
    "            min_rec = audio_rec\n",
    "        if phone_len > max_len:\n",
    "            max_len = phone_len\n",
    "            max_rec = audio_rec\n",
    "        all_len.append(phone_len)\n",
    "    return min_len, max_len, min_rec, max_rec, all_len\n",
    "\n",
    "\n",
    "# Given an audio dataset, shows the audio length disribution\n",
    "def showAudioLenDisrib(audio_ds):\n",
    "    # Print min/max info\n",
    "    min_len, max_len, min_rec, max_rec, all_len = getMinMaxRec(audio_ds)\n",
    "    print('min_rec:', min_len, min_rec[0])\n",
    "    print('max_rec:', max_len, max_rec[0])\n",
    "    median = np.median(all_len)\n",
    "    print('median:', median)\n",
    "    \n",
    "    # show min-rec waveform\n",
    "    wave, rate = min_rec[1:]\n",
    "    print('min_rec waveform:')\n",
    "    plt.plot(wave)\n",
    "    plt.show()\n",
    "    \n",
    "    # Play the audio clips\n",
    "    ipd.display(ipd.Audio(wave, rate=rate))\n",
    "    wave, rate = max_rec[1:]\n",
    "    ipd.display(ipd.Audio(wave, rate=rate))\n",
    "    \n",
    "    # Show the histogram\n",
    "    plt.hist(all_len, bins='auto', rwidth=0.8)\n",
    "    plt.xlabel('Value')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Distribution of audio lengths')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e66c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train_audio_ds ---')\n",
    "showAudioLenDisrib(Train_audio_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0b2127",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Test_audio_ds ---')\n",
    "showAudioLenDisrib(Test_audio_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ec94a9",
   "metadata": {},
   "source": [
    "## Zero Padding of Short Audio\n",
    "\n",
    "**NOTE:**\n",
    "Based on the above observation\n",
    "- Because median is around 1024, pad zeros to make all audio length >= 1024."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f769ccc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given an audio dataset, pad zeros to make all audio clips lengths >= min_len\n",
    "# audio_ds[i]: (phoneme, wave, rate)\n",
    "def padZeroAudio(audio_ds, min_len):\n",
    "    for audio_rec in audio_ds:\n",
    "        current_length = len(audio_rec[1])\n",
    "        if current_length < min_len:\n",
    "            num_zeros = min_len - current_length\n",
    "            padding = np.zeros(num_zeros)\n",
    "            padded_audio = np.concatenate((audio_rec[1], padding))\n",
    "            audio_rec[1] = padded_audio\n",
    "\n",
    "            \n",
    "# Pad zeros to audio\n",
    "F_min_audio_len = 1024\n",
    "padZeroAudio(Train_audio_ds, F_min_audio_len)\n",
    "padZeroAudio(Test_audio_ds, F_min_audio_len)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527d3141",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train_audio_ds ---')\n",
    "showAudioLenDisrib(Train_audio_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db933e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Test_audio_ds ---')\n",
    "showAudioLenDisrib(Test_audio_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04cac9ba",
   "metadata": {},
   "source": [
    "# Data Augmentation\n",
    "\n",
    "Data augmentation is performed to avoid over-fitting on the training dataset. This can potentially improve accuracy over the unknown data points."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4709c721",
   "metadata": {},
   "source": [
    "## Design Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9933d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adds noise to the audio\n",
    "def add_noise(waveform, noise_factor):\n",
    "    noise = np.random.rand(len(waveform))\n",
    "    noisy_audio = waveform + noise_factor * noise\n",
    "    return noisy_audio\n",
    "\n",
    "\n",
    "# Changes the audio volume\n",
    "def change_volume(waveform, volume_factor):  \n",
    "    scaled_audio = waveform * volume_factor\n",
    "    return scaled_audio\n",
    "\n",
    "\n",
    "# Shifts audio pitch\n",
    "def pitch_shift(waveform, sample_rate, n_steps):\n",
    "    shifted_audio = librosa.effects.pitch_shift(waveform, sr=sample_rate, n_steps=n_steps, n_fft=256)\n",
    "    return shifted_audio\n",
    "\n",
    "\n",
    "# Increases the audio speed\n",
    "def speed_change(waveform, speed):\n",
    "    speedup_audio = librosa.effects.time_stretch(waveform, rate=speed, n_fft=256)\n",
    "    return speedup_audio\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc54f92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_keys = list(audio_cache.keys())\n",
    "wave, rate = audio_cache[audio_keys[100]]\n",
    "print('original audio')\n",
    "ipd.Audio(wave, rate=rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f7a51b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Applies the augmentation and shows the audio widget with the new waveform\n",
    "def testAugmentation(augmenter, waveform, rate, **options):\n",
    "    new_wave = augmenter(waveform, **options)\n",
    "    ipd.display(ipd.Audio(new_wave, rate=rate))\n",
    "    ax_org = plt.subplot(1,2,1)\n",
    "    ax_new = plt.subplot(1,2,2)\n",
    "    ax_org.plot(waveform)\n",
    "    ax_new.plot(new_wave)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "\n",
    "# Test the augmentations\n",
    "print('add_noise')\n",
    "testAugmentation(add_noise, wave, rate, noise_factor=0.002)  # factor range: 0.002 - 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e21a9f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('change_volume')\n",
    "testAugmentation(change_volume, wave, rate, volume_factor=1.5)  # factor range: 0.2 - 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9bed183",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('pitch_shift')\n",
    "testAugmentation(pitch_shift, wave, rate, sample_rate=rate, n_steps=2)    # n_steps: -2 to 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa15db4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('speed_change')\n",
    "testAugmentation(speed_change, wave, rate, speed=0.85)   # speed range: 0.85 - 1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460e85dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "del audio_keys, wave, rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f90b514",
   "metadata": {},
   "source": [
    "## Build Augmented Audio Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa22b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define augmentation functions with randomized parameters\n",
    "import random\n",
    "\n",
    "\n",
    "def augment_noise(waveform, rate):\n",
    "    factor_min, factor_max = 0.002, 0.005\n",
    "    factor = random.uniform(factor_min, factor_max)\n",
    "    return add_noise(waveform, noise_factor=factor)\n",
    "\n",
    "\n",
    "def augment_volume(waveform, rate):\n",
    "    factor_min, factor_max = 0.2, 1.5\n",
    "    factor = random.uniform(factor_min, factor_max)\n",
    "    return change_volume(waveform, volume_factor=factor)\n",
    "\n",
    "\n",
    "def augment_pitch(waveform, rate):\n",
    "    step_min, step_max = 0.2, 1.5\n",
    "    step = random.uniform(-2, 2)\n",
    "    return pitch_shift(waveform, sample_rate=rate, n_steps=step)\n",
    "\n",
    "\n",
    "def augment_speed(waveform, rate):\n",
    "    speed_min, speed_max = 0.85, 1.2\n",
    "    speed = random.uniform(speed_min, speed_max)\n",
    "    return speed_change(waveform, speed=speed)\n",
    "    \n",
    "\n",
    "    \n",
    "# Given an audio dataset and a set of augmentations functions\n",
    "# returns a new dataset with random augmentations applied.\n",
    "# prototype of all_augments[i]: (waveform, rate)\n",
    "def makeAugmentedDS(audio_ds, all_augments):\n",
    "    rmin, rmax = 0, len(all_augments) - 1     # index range for selection\n",
    "    new_audio_ds = []\n",
    "    for item in tqdm(audio_ds):\n",
    "        augment_select = random.randint(rmin, rmax)\n",
    "        phone, wave, rate = item\n",
    "        new_wave = all_augments[augment_select](wave, rate)\n",
    "        new_audio_ds.append([phone, new_wave, rate])\n",
    "    return new_audio_ds\n",
    "    \n",
    "    \n",
    "    \n",
    "#Train_audio_ds = makeAudioDS(Train_ds)\n",
    "Train_aug_audio_ds = makeAugmentedDS(Train_audio_ds, [augment_noise, augment_volume, augment_pitch, augment_speed])\n",
    "print('Train_aug_audio_ds:', len(Train_aug_audio_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf09315",
   "metadata": {},
   "outputs": [],
   "source": [
    "select_index = 2\n",
    "item = Train_audio_ds[select_index]\n",
    "ipd.display(ipd.Audio(item[1], rate=item[2]))\n",
    "\n",
    "item = Train_aug_audio_ds[select_index]\n",
    "ipd.display(ipd.Audio(item[1], rate=item[2]))\n",
    "\n",
    "del select_index, item"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3e9810",
   "metadata": {},
   "source": [
    "# Feature Extraction, Normalization, and Export"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb8256e",
   "metadata": {},
   "source": [
    "## Build Feature Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6caed11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "F_fft_window = 512\n",
    "F_hop_length = 64\n",
    "F_n_mels = 40\n",
    "\n",
    "F_note = f'''\n",
    "F_n_mels    : {F_n_mels}\n",
    "F_fft_window: {F_fft_window}\n",
    "F_hop_length: {F_hop_length}\n",
    "'''\n",
    "\n",
    "# Given an audio record, returns a feature record: (phoneme, feature-sequence)\n",
    "def getFeatureRecord(audio_record):\n",
    "    # Feature extraction parameters\n",
    "    # Extract features from the audio-record\n",
    "    phone, wave, rate = audio_record\n",
    "    # compute mel-spectrogram\n",
    "    mel_spec = getMelSpec(wave, rate, n_mels=F_n_mels, fft_window=F_fft_window, hop_length=F_hop_length)\n",
    "    # Compute energy from mfcc then stack on top of mfcc for deta calculation\n",
    "    energy = getEnergy(wave, frame_length=F_fft_window, hop_length=F_hop_length)\n",
    "    mel_eng = np.vstack([mel_spec, energy])\n",
    "    # compute deltas\n",
    "    delta1 = getDelta(mel_eng, order=1)\n",
    "    delta2 = getDelta(mel_eng, order=2)\n",
    "    # stack all to make feature vector\n",
    "    feat_vec = np.vstack([mel_eng, delta1, delta2])\n",
    "    return [phone, feat_vec]    # make each record a list, not a tuple for easier modification later\n",
    "\n",
    "    \n",
    "# Test above function\n",
    "audio_rec = Train_audio_ds[4]\n",
    "phone, feat_vec = getFeatureRecord(audio_rec)\n",
    "print('phone:', phone)\n",
    "print('audio_rec[1]:', len(audio_rec[1]))\n",
    "print('feat_vec:', feat_vec.shape)\n",
    "F_feat_len = len(feat_vec)\n",
    "ipd.display(ipd.Audio(audio_rec[1], rate=audio_rec[2]))\n",
    "\n",
    "\n",
    "# delete redundant variables to avoid confusion\n",
    "del audio_rec, phone, feat_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc1089b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given a feature-sequence, breaks down different parts then plots it\n",
    "def showFeatures(feature_sequence):    # feature_sequence: (sequence-point, feature-vector)    \n",
    "    feat_seq = feature_sequence\n",
    "    fig = plt.figure(figsize=(12, 5))\n",
    "    fig.subplots_adjust(hspace=0.5)\n",
    "    fig.tight_layout()\n",
    "\n",
    "    mel_coeff = feat_seq[0:40, :]     # extract the mel coefficients only\n",
    "    ax_mel = fig.add_subplot(2, 2, 1)\n",
    "    ax_mel.set_title('Mel Coefficients')\n",
    "    plotSpecshow(mel_coeff, fig, ax_mel)\n",
    "\n",
    "    energy = feat_seq[40, :]     # extract energy only\n",
    "    ax_energy = fig.add_subplot(2, 2, 2)\n",
    "    ax_energy.set_title('Energy')\n",
    "    ax_energy.plot(energy)\n",
    "    \n",
    "    delta1 = feat_seq[41:82, :]  # extract delta1 only\n",
    "    ax_delta1 = fig.add_subplot(2, 2, 3)\n",
    "    ax_delta1.set_title('Delta-1')\n",
    "    plotSpecshow(delta1, fig, ax_delta1)\n",
    "\n",
    "    delta2 = feat_seq[82:, :]    # extract delta2 only\n",
    "    ax_delta2 = fig.add_subplot(2, 2, 4)\n",
    "    ax_delta2.set_title('Delta-2')\n",
    "    plotSpecshow(delta2, fig, ax_delta2)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b273fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given an audio dataset, returns a list of feature dataset\n",
    "# audio_ds[i]: (phone, wave, rate)\n",
    "# return[i]: (phone, feature-sequence)\n",
    "def makeFeatureDS(audio_ds):\n",
    "    feat_ds = []\n",
    "    for audio_rec in tqdm(audio_ds):\n",
    "        feat_rec = getFeatureRecord(audio_rec)\n",
    "        feat_ds.append(feat_rec)\n",
    "    return feat_ds\n",
    "\n",
    "\n",
    "# Build feature datasets\n",
    "Train_feat_ds     = makeFeatureDS(Train_audio_ds)\n",
    "Train_aug_feat_ds = makeFeatureDS(Train_aug_audio_ds)\n",
    "Test_feat_ds      = makeFeatureDS(Test_audio_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e188c0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "item = Train_feat_ds[0]\n",
    "showFeatures(item[1])\n",
    "del item"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18eb6b63",
   "metadata": {},
   "source": [
    "## Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a31b35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given a list of sequences, flattens it into a 1D array\n",
    "def makeFlattened(sequence_list):\n",
    "    # merge and flatten\n",
    "    out_list = []\n",
    "    for index, seq in enumerate(sequence_list):\n",
    "        out_list.append(seq.flatten())        # make flattened copies of the sequences\n",
    "    out_list = np.concatenate(out_list)\n",
    "    out_list = out_list.flatten()\n",
    "    return out_list\n",
    "    \n",
    "\n",
    "# Given a list of features, returns their mean and standard deviation\n",
    "def getMeanStd(all_features, flattened=False):\n",
    "    # merge and flatten if necessary\n",
    "    if not flattened: all_features = makeFlattened(all_features)\n",
    "    # Get mean and standard deviation\n",
    "    mean = np.mean(all_features)\n",
    "    std  = np.std(all_features)\n",
    "    return mean, std\n",
    "\n",
    "\n",
    "# Show the histogram\n",
    "def plotHistogram(array):\n",
    "    plt.hist(array, bins='auto', rwidth=0.8)\n",
    "    plt.xlabel('Value')\n",
    "    plt.ylabel('Frequency')\n",
    "    \n",
    "        \n",
    "# Given a feature-dataset, returns different parts of the feature vector as lists\n",
    "def separateFeatures(feat_ds):\n",
    "    all_mel = [item[1][0:40, :] for item in feat_ds]\n",
    "    all_energy = [item[1][40, :] for item in feat_ds]\n",
    "    all_delta1 = [item[1][41:82, :] for item in feat_ds]\n",
    "    all_delta2 = [item[1][82:123, :] for item in feat_ds]\n",
    "    return all_mel, all_energy, all_delta1, all_delta2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Test above function\n",
    "all_mel, all_energy, all_delta1, all_delta2 = separateFeatures(Test_feat_ds)\n",
    "array = makeFlattened(all_energy)\n",
    "mean, std = getMeanStd(array)\n",
    "plotHistogram(array)\n",
    "print('mean:', mean, \"   std:\", std)\n",
    "del all_mel, all_energy, all_delta1, all_delta2\n",
    "del array, mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc982ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given a list of features, returns dynarmic range-related parameters\n",
    "def getDynRange(all_features):\n",
    "    # Merge and Flatten\n",
    "    all_features = makeFlattened(all_features)\n",
    "    all_feat_0 = all_features[all_features!=0]     # remove all zeros\n",
    "    # Compute dynamic range-related information\n",
    "    min_all = np.min(all_features)\n",
    "    max_all = np.max(all_features)\n",
    "    min_abs = np.min(np.abs(all_features))\n",
    "    max_abs = np.max(np.abs(all_features))\n",
    "    min_abs_0 = np.min(np.abs(all_feat_0))\n",
    "    mean, std = getMeanStd(all_features, flattened=True)\n",
    "    return min_all, max_all, min_abs, max_abs, min_abs_0, mean, std\n",
    "\n",
    "\n",
    "# Printing utility for dynamic range parameters\n",
    "def printDynRangeParams(min_all, max_all, min_abs, max_abs, min_abs_0, mean, std):\n",
    "    print('min_all  :', min_all)\n",
    "    print('max_all  :', max_all)\n",
    "    print('min_abs  :', min_abs)\n",
    "    print('max_abs  :', max_abs)\n",
    "    print('min_abs_0:', min_abs_0)\n",
    "    print('mean     :', mean)\n",
    "    print('std      :', std)\n",
    "\n",
    "    \n",
    "# Given a feature-dataset, prints the dynamic ranges of different sections of the feature-vector\n",
    "def printAllRange(feat_ds):\n",
    "    all_feat = [item[1] for item in feat_ds]\n",
    "    all_mel, all_energy, all_delta1, all_delta2 = separateFeatures(feat_ds)\n",
    "     \n",
    "    # Dynamic range of entire feature vector\n",
    "    range_params = getDynRange(all_feat)\n",
    "    print('[all_feat]')\n",
    "    printDynRangeParams(*range_params)\n",
    "\n",
    "    # Dynamic range of mel-coefficients\n",
    "    range_params = getDynRange(all_mel)\n",
    "    print('\\n[all_mel]')\n",
    "    printDynRangeParams(*range_params)\n",
    "\n",
    "    # Dynamic range of energy\n",
    "    range_params = getDynRange(all_energy)\n",
    "    print('\\n[all_energy]')\n",
    "    printDynRangeParams(*range_params)\n",
    "\n",
    "    # Dynamic range of delta-1\n",
    "    range_params = getDynRange(all_delta1)\n",
    "    print('\\n[all_delta1]')\n",
    "    printDynRangeParams(*range_params)\n",
    "\n",
    "    # Dynamic range of delta-2\n",
    "    range_params = getDynRange(all_delta2)\n",
    "    print('\\n[all_delta2]')\n",
    "    printDynRangeParams(*range_params)\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "# Print the dynamic ranges before normalization\n",
    "print('Dynamic Ranges before normalization')\n",
    "print('---- Test_feat_ds ----')\n",
    "printAllRange(Test_feat_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb02b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('---- Train_feat_ds ----')\n",
    "printAllRange(Train_feat_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d5f14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('---- Train_aug_feat_ds ----')\n",
    "printAllRange(Train_aug_feat_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6b3142",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "# Given a feature dataset, returns the mean and std of each feature subset\n",
    "def getNormalizationParams(feature_ds):\n",
    "    all_mel, all_energy, all_delta1, all_delta2 = separateFeatures(feature_ds)\n",
    "    mel_mean, mel_std = getMeanStd(all_mel)\n",
    "    eng_mean, eng_std = getMeanStd(all_energy)\n",
    "    d1_mean, d1_std = getMeanStd(all_delta1)\n",
    "    d2_mean, d2_std = getMeanStd(all_delta2)        \n",
    "    return (mel_mean, mel_std), (eng_mean, eng_std), (d1_mean, d1_std), (d2_mean, d2_std)\n",
    "\n",
    "\n",
    "# Given a feature dataset and normalization parameters, normalizes the feature subsets\n",
    "def normalizeFeatures(feature_ds, normal_params):\n",
    "    # Unpack normalization parameters\n",
    "    (mel_mean, mel_std), \\\n",
    "    (eng_mean, eng_std), \\\n",
    "    (d1_mean, d1_std), \\\n",
    "    (d2_mean, d2_std)  = normal_params\n",
    "    eps = 1e-4            # replacement for zero\n",
    "    feat_ds_copy = deepcopy(feature_ds)    # don't modify original dataset\n",
    "    \n",
    "    # Normalize mel-coefficients\n",
    "    mean, std = mel_mean, mel_std\n",
    "    print(f'INFO: Normalizing mel-coefficients, mean: {mean}   std: {std}')\n",
    "    if std == 0: std = eps           # avoid division by zero\n",
    "    for item in feat_ds_copy:\n",
    "        mels = item[1][0:40, :]\n",
    "        item[1][0:40, :] = (mels - mean) / std\n",
    "    \n",
    "    # normalize energy\n",
    "    mean, std = eng_mean, eng_std\n",
    "    print(f'INFO: Normalizing energy, mean: {mean}   std: {std}')\n",
    "    if std == 0: std = eps           # avoid division by zero\n",
    "    for item in feat_ds_copy:\n",
    "        energy = item[1][40, :]\n",
    "        item[1][40, :] = (energy - mean) / std\n",
    "    \n",
    "    # normalize delta-1\n",
    "    mean, std = d1_mean, d1_std\n",
    "    print(f'INFO: Normalizing delta-1, mean: {mean}   std: {std}')\n",
    "    if std == 0: std = eps           # avoid division by zero\n",
    "    for item in feat_ds_copy:\n",
    "        delta1 = item[1][41:82, :]\n",
    "        item[1][41:82, :] = (delta1 - mean) / std\n",
    "    \n",
    "    # normalize delta-2\n",
    "    mean, std = d2_mean, d2_std\n",
    "    print(f'INFO: Normalizing delta-2, mean: {mean}   std: {std}')\n",
    "    if std == 0: std = eps           # avoid division by zero\n",
    "    for item in feat_ds_copy:\n",
    "        delta2 = item[1][82:123, :]\n",
    "        item[1][82:123, :] = (delta2 - mean) / std\n",
    "        \n",
    "    return feat_ds_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78ffcc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize Train and Test features using Train normalization parameters\n",
    "train_normal_params = getNormalizationParams(Train_feat_ds)\n",
    "Test_norm_feat_ds = normalizeFeatures(Test_feat_ds, normal_params=train_normal_params)\n",
    "Train_norm_feat_ds = normalizeFeatures(Train_feat_ds, normal_params=train_normal_params)\n",
    "Train_norm_aug_feat_ds = normalizeFeatures(Train_aug_feat_ds, normal_params=train_normal_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f010d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nDynamic Ranges after normalization')\n",
    "print('---- Test_norm_feat_ds ----')\n",
    "printAllRange(Test_norm_feat_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8023751d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('---- Train_norm_feat_ds ----')\n",
    "printAllRange(Train_norm_feat_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e4e79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('---- Train_norm_aug_feat_ds ----')\n",
    "printAllRange(Train_norm_aug_feat_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be009e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "Normal_params = train_normal_params\n",
    "item = Test_norm_feat_ds[0]\n",
    "showFeatures(item[1])\n",
    "del item, train_normal_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3e7bb9",
   "metadata": {},
   "source": [
    "## Export Normalized Feature Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39783e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete extra datasets to save memory\n",
    "del Train_ds, Train_audio_ds, Train_feat_ds\n",
    "del Test_ds, Test_audio_ds, Test_feat_ds\n",
    "del Train_aug_audio_ds, Train_aug_feat_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abae801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the dataset with necessary information for the next notebook\n",
    "normal_param_scheme = '(mel_mean, mel_std), (eng_mean, eng_std), (d1_mean, d1_std), (d2_mean, d2_std)'\n",
    "note = f'''\n",
    "Notes:\n",
    "- Feature record: (phone, feature_sequence)\n",
    "- Feature_seqence: list(feature_vector)\n",
    "- Normalization params: {normal_param_scheme}\n",
    "- len(feature_vector): {F_feat_len}\n",
    "\n",
    "Normalization Parameters:\n",
    "{Normal_params}\n",
    "\n",
    "Features are extracted using following parameters''' + F_note\n",
    "\n",
    "print(note)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bb68e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given a feature-dataset, saves in a file\n",
    "def saveFeatureDS(feat_ds, save_path, note):\n",
    "    export = {\n",
    "        'note' : note,\n",
    "        'data-schema' : '(phoneme, feature-sequence)',\n",
    "        'normal_params' : Normal_params,\n",
    "        'data' : feat_ds\n",
    "    }\n",
    "    torch.save(export, save_path)\n",
    "    print(f'INFO: Saved {save_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e66877",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make test feature dataset then save\n",
    "saveFeatureDS(Test_norm_feat_ds, './session/test-norm-features.pt', note)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b374fcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "saveFeatureDS(Train_norm_feat_ds, './session/train-norm-features.pt', note)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd43fe43",
   "metadata": {},
   "outputs": [],
   "source": [
    "saveFeatureDS(Train_norm_aug_feat_ds, './session/train-norm-aug-features.pt', note)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4bd36a9",
   "metadata": {},
   "source": [
    "# Label-to-Index Mapping and Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d9d258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export Label-to-index map\n",
    "export_labels = False\n",
    "\n",
    "\n",
    "# Given an audio dataset, returns the set of all labels\n",
    "def getAllLabels(audio_ds):\n",
    "    labels = set()\n",
    "    for item in audio_ds:     # item: (label, feature-sequence)\n",
    "        labels.add(item[0])\n",
    "    return labels\n",
    "\n",
    "\n",
    "# Build the labels dictionary\n",
    "all_train_labels = getAllLabels(Train_audio_ds)\n",
    "all_test_labels  = getAllLabels(Test_audio_ds)\n",
    "print('all_train_labels:', len(all_train_labels), '\\n', all_train_labels)\n",
    "print('all_test_labels :', len(all_test_labels) , '\\n', all_test_labels)\n",
    "\n",
    "print('')\n",
    "Label_to_index = {label:index for index, label in enumerate(all_train_labels)}\n",
    "Index_to_label = {index:label for label, index in Label_to_index.items()}\n",
    "print('Label_to_index:\\n', Label_to_index)\n",
    "print('Index_to_label:\\n', Index_to_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4180f02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if export_labels:\n",
    "    save_path = './session/label-to-index.pt'\n",
    "    torch.save(Label_to_index, save_path)\n",
    "    !ls -ltrh ./session"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
